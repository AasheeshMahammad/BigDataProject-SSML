21/12/06 17:37:04 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.0.148 instead (on interface ens33)
21/12/06 17:37:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
21/12/06 17:37:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/12/06 17:37:06 INFO SparkContext: Running Spark version 3.1.2
21/12/06 17:37:06 INFO ResourceUtils: ==============================================================
21/12/06 17:37:06 INFO ResourceUtils: No custom resources configured for spark.driver.
21/12/06 17:37:06 INFO ResourceUtils: ==============================================================
21/12/06 17:37:06 INFO SparkContext: Submitted application: crime_data
21/12/06 17:37:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/12/06 17:37:06 INFO ResourceProfile: Limiting resource is cpu
21/12/06 17:37:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/12/06 17:37:06 INFO SecurityManager: Changing view acls to: pes2ug19cs342
21/12/06 17:37:06 INFO SecurityManager: Changing modify acls to: pes2ug19cs342
21/12/06 17:37:06 INFO SecurityManager: Changing view acls groups to: 
21/12/06 17:37:06 INFO SecurityManager: Changing modify acls groups to: 
21/12/06 17:37:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pes2ug19cs342); groups with view permissions: Set(); users  with modify permissions: Set(pes2ug19cs342); groups with modify permissions: Set()
21/12/06 17:37:06 INFO Utils: Successfully started service 'sparkDriver' on port 35859.
21/12/06 17:37:06 INFO SparkEnv: Registering MapOutputTracker
21/12/06 17:37:06 INFO SparkEnv: Registering BlockManagerMaster
21/12/06 17:37:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/12/06 17:37:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/12/06 17:37:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/12/06 17:37:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-66259dae-bda2-423d-aa2c-e90666a16645
21/12/06 17:37:06 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
21/12/06 17:37:06 INFO SparkEnv: Registering OutputCommitCoordinator
21/12/06 17:37:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/12/06 17:37:06 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.148:4040
21/12/06 17:37:06 INFO Executor: Starting executor ID driver on host 192.168.0.148
21/12/06 17:37:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33235.
21/12/06 17:37:06 INFO NettyBlockTransferService: Server created on 192.168.0.148:33235
21/12/06 17:37:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/12/06 17:37:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.148, 33235, None)
21/12/06 17:37:06 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.148:33235 with 434.4 MiB RAM, BlockManagerId(driver, 192.168.0.148, 33235, None)
21/12/06 17:37:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.148, 33235, None)
21/12/06 17:37:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.148, 33235, None)
21/12/06 17:37:07 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/pes2ug19cs342/Desktop/BigDataProject-SSML/Model1_BernoulliNB/spark-warehouse').
21/12/06 17:37:07 INFO SharedState: Warehouse path is 'file:/home/pes2ug19cs342/Desktop/BigDataProject-SSML/Model1_BernoulliNB/spark-warehouse'.
21/12/06 17:37:08 INFO ReceiverTracker: Starting 1 receivers
21/12/06 17:37:08 INFO ReceiverTracker: ReceiverTracker started
21/12/06 17:37:08 INFO SocketInputDStream: Slide time = 1000 ms
21/12/06 17:37:08 INFO SocketInputDStream: Storage level = Serialized 1x Replicated
21/12/06 17:37:08 INFO SocketInputDStream: Checkpoint interval = null
21/12/06 17:37:08 INFO SocketInputDStream: Remember interval = 1000 ms
21/12/06 17:37:08 INFO SocketInputDStream: Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@4e0e35e1
21/12/06 17:37:08 INFO ForEachDStream: Slide time = 1000 ms
21/12/06 17:37:08 INFO ForEachDStream: Storage level = Serialized 1x Replicated
21/12/06 17:37:08 INFO ForEachDStream: Checkpoint interval = null
21/12/06 17:37:08 INFO ForEachDStream: Remember interval = 1000 ms
21/12/06 17:37:08 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@7034db55
21/12/06 17:37:08 INFO ReceiverTracker: Receiver 0 started
21/12/06 17:37:08 INFO DAGScheduler: Got job 0 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/12/06 17:37:08 INFO DAGScheduler: Final stage: ResultStage 0 (start at NativeMethodAccessorImpl.java:0)
21/12/06 17:37:08 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:08 INFO RecurringTimer: Started timer for JobGenerator at time 1638792429000
21/12/06 17:37:08 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:08 INFO JobGenerator: Started JobGenerator at 1638792429000 ms
21/12/06 17:37:08 INFO DAGScheduler: Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609), which has no missing parents
21/12/06 17:37:08 INFO JobScheduler: Started JobScheduler
21/12/06 17:37:08 INFO StreamingContext: StreamingContext started
21/12/06 17:37:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 81.5 KiB, free 434.3 MiB)
21/12/06 17:37:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.7 KiB, free 434.3 MiB)
21/12/06 17:37:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.148:33235 (size: 28.7 KiB, free: 434.4 MiB)
21/12/06 17:37:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[0] at makeRDD at ReceiverTracker.scala:609) (first 15 tasks are for partitions Vector(0))
21/12/06 17:37:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
21/12/06 17:37:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 5478 bytes) taskResourceAssignments Map()
21/12/06 17:37:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/12/06 17:37:08 INFO RecurringTimer: Started timer for BlockGenerator at time 1638792428600
21/12/06 17:37:08 INFO BlockGenerator: Started BlockGenerator
21/12/06 17:37:08 INFO BlockGenerator: Started block pushing thread
21/12/06 17:37:08 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:37:08 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:37:08 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:37:08 INFO SocketReceiver: Connected to localhost:6100
21/12/06 17:37:08 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:37:08 INFO ReceiverSupervisorImpl: Waiting for receiver to be stopped
21/12/06 17:37:09 INFO JobScheduler: Added jobs for time 1638792429000 ms
21/12/06 17:37:09 INFO JobScheduler: Starting job streaming job 1638792429000 ms.0 from job set of time 1638792429000 ms
21/12/06 17:37:09 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:09 INFO DAGScheduler: Job 1 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.001066 s
21/12/06 17:37:09 INFO JobScheduler: Finished job streaming job 1638792429000 ms.0 from job set of time 1638792429000 ms
21/12/06 17:37:09 INFO JobScheduler: Total delay: 0.111 s for time 1638792429000 ms (execution: 0.087 s)
21/12/06 17:37:09 INFO ReceivedBlockTracker: Deleting batches: 
21/12/06 17:37:09 INFO InputInfoTracker: remove old batch metadata: 
21/12/06 17:37:10 INFO JobScheduler: Added jobs for time 1638792430000 ms
21/12/06 17:37:10 INFO JobScheduler: Starting job streaming job 1638792430000 ms.0 from job set of time 1638792430000 ms
21/12/06 17:37:10 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:10 INFO DAGScheduler: Job 2 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000168 s
21/12/06 17:37:10 INFO JobScheduler: Finished job streaming job 1638792430000 ms.0 from job set of time 1638792430000 ms
21/12/06 17:37:10 INFO JobScheduler: Total delay: 0.028 s for time 1638792430000 ms (execution: 0.026 s)
21/12/06 17:37:10 INFO BlockRDD: Removing RDD 1 from persistence list
21/12/06 17:37:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[1] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792430000 ms
21/12/06 17:37:10 INFO ReceivedBlockTracker: Deleting batches: 
21/12/06 17:37:10 INFO InputInfoTracker: remove old batch metadata: 
21/12/06 17:37:10 INFO BlockManager: Removing RDD 1
21/12/06 17:37:11 INFO JobScheduler: Added jobs for time 1638792431000 ms
21/12/06 17:37:11 INFO JobScheduler: Starting job streaming job 1638792431000 ms.0 from job set of time 1638792431000 ms
21/12/06 17:37:11 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:11 INFO DAGScheduler: Job 3 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000277 s
21/12/06 17:37:11 INFO JobScheduler: Finished job streaming job 1638792431000 ms.0 from job set of time 1638792431000 ms
21/12/06 17:37:11 INFO JobScheduler: Total delay: 0.037 s for time 1638792431000 ms (execution: 0.035 s)
21/12/06 17:37:11 INFO BlockRDD: Removing RDD 2 from persistence list
21/12/06 17:37:11 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[2] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792431000 ms
21/12/06 17:37:11 INFO ReceivedBlockTracker: Deleting batches: 1638792429000 ms
21/12/06 17:37:11 INFO InputInfoTracker: remove old batch metadata: 1638792429000 ms
21/12/06 17:37:11 INFO BlockManager: Removing RDD 2
21/12/06 17:37:12 INFO JobScheduler: Added jobs for time 1638792432000 ms
21/12/06 17:37:12 INFO JobScheduler: Starting job streaming job 1638792432000 ms.0 from job set of time 1638792432000 ms
21/12/06 17:37:12 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:12 INFO DAGScheduler: Job 4 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000152 s
21/12/06 17:37:12 INFO JobScheduler: Finished job streaming job 1638792432000 ms.0 from job set of time 1638792432000 ms
21/12/06 17:37:12 INFO JobScheduler: Total delay: 0.020 s for time 1638792432000 ms (execution: 0.018 s)
21/12/06 17:37:12 INFO BlockRDD: Removing RDD 3 from persistence list
21/12/06 17:37:12 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[3] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792432000 ms
21/12/06 17:37:12 INFO ReceivedBlockTracker: Deleting batches: 1638792430000 ms
21/12/06 17:37:12 INFO InputInfoTracker: remove old batch metadata: 1638792430000 ms
21/12/06 17:37:12 INFO BlockManager: Removing RDD 3
21/12/06 17:37:12 INFO MemoryStore: Block input-0-1638792432000 stored as values in memory (estimated size 54.5 MiB, free 379.8 MiB)
21/12/06 17:37:12 INFO BlockManagerInfo: Added input-0-1638792432000 in memory on 192.168.0.148:33235 (size: 54.5 MiB, free: 379.9 MiB)
21/12/06 17:37:12 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/06 17:37:12 WARN BlockManager: Block input-0-1638792432000 replicated to only 0 peer(s) instead of 1 peers
21/12/06 17:37:12 INFO BlockGenerator: Pushed block input-0-1638792432000
21/12/06 17:37:13 INFO JobScheduler: Added jobs for time 1638792433000 ms
21/12/06 17:37:13 INFO JobScheduler: Starting job streaming job 1638792433000 ms.0 from job set of time 1638792433000 ms
21/12/06 17:37:13 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:13 INFO DAGScheduler: Got job 5 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/06 17:37:13 INFO DAGScheduler: Final stage: ResultStage 1 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:13 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:13 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:13 INFO DAGScheduler: Submitting ResultStage 1 (BlockRDD[5] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/06 17:37:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1968.0 B, free 379.8 MiB)
21/12/06 17:37:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1208.0 B, free 379.8 MiB)
21/12/06 17:37:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.148:33235 (size: 1208.0 B, free: 379.9 MiB)
21/12/06 17:37:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (BlockRDD[5] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/06 17:37:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
21/12/06 17:37:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/06 17:37:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/12/06 17:37:13 INFO BlockManager: Found block input-0-1638792432000 locally
21/12/06 17:37:13 INFO MemoryStore: Block taskresult_1 stored as bytes in memory (estimated size 54.8 MiB, free 325.0 MiB)
21/12/06 17:37:13 INFO BlockManagerInfo: Added taskresult_1 in memory on 192.168.0.148:33235 (size: 54.8 MiB, free: 325.1 MiB)
21/12/06 17:37:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 57437541 bytes result sent via BlockManager)
21/12/06 17:37:13 INFO TransportClientFactory: Successfully created connection to /192.168.0.148:33235 after 25 ms (0 ms spent in bootstraps)
21/12/06 17:37:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 836 ms on 192.168.0.148 (executor driver) (1/1)
21/12/06 17:37:13 INFO BlockManagerInfo: Removed taskresult_1 on 192.168.0.148:33235 in memory (size: 54.8 MiB, free: 379.9 MiB)
21/12/06 17:37:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/12/06 17:37:13 INFO DAGScheduler: ResultStage 1 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.858 s
21/12/06 17:37:13 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/12/06 17:37:13 INFO DAGScheduler: Job 5 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.871420 s
21/12/06 17:37:13 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.148:33235 in memory (size: 1208.0 B, free: 379.9 MiB)
21/12/06 17:37:14 INFO JobScheduler: Added jobs for time 1638792434000 ms
21/12/06 17:37:15 INFO JobScheduler: Added jobs for time 1638792435000 ms
21/12/06 17:37:16 INFO JobScheduler: Added jobs for time 1638792436000 ms
21/12/06 17:37:17 INFO JobScheduler: Added jobs for time 1638792437000 ms
21/12/06 17:37:18 INFO JobScheduler: Added jobs for time 1638792438000 ms
21/12/06 17:37:18 INFO CodeGenerator: Code generated in 308.401247 ms
21/12/06 17:37:18 INFO CodeGenerator: Code generated in 9.330575 ms
21/12/06 17:37:18 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:18 INFO DAGScheduler: Got job 6 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/12/06 17:37:18 INFO DAGScheduler: Final stage: ResultStage 2 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:18 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:18 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:18 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[25] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/12/06 17:37:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 28.0 KiB, free 379.8 MiB)
21/12/06 17:37:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 379.7 MiB)
21/12/06 17:37:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.148:33235 (size: 11.4 KiB, free: 379.9 MiB)
21/12/06 17:37:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[25] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/12/06 17:37:18 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks resource profile 0
21/12/06 17:37:18 WARN TaskSetManager: Stage 2 contains a task of very large size (14004 KiB). The maximum recommended task size is 1000 KiB.
21/12/06 17:37:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 14341093 bytes) taskResourceAssignments Map()
21/12/06 17:37:18 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/12/06 17:37:19 INFO JobScheduler: Added jobs for time 1638792439000 ms
21/12/06 17:37:19 INFO MemoryStore: Block input-0-1638792439000 stored as values in memory (estimated size 54.6 MiB, free 325.2 MiB)
21/12/06 17:37:19 INFO BlockManagerInfo: Added input-0-1638792439000 in memory on 192.168.0.148:33235 (size: 54.6 MiB, free: 325.3 MiB)
21/12/06 17:37:19 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/06 17:37:19 WARN BlockManager: Block input-0-1638792439000 replicated to only 0 peer(s) instead of 1 peers
21/12/06 17:37:19 INFO BlockGenerator: Pushed block input-0-1638792439000
21/12/06 17:37:20 INFO JobScheduler: Added jobs for time 1638792440000 ms
21/12/06 17:37:20 INFO PythonRunner: Times: total = 1526, boot = 539, init = 8, finish = 979
21/12/06 17:37:21 INFO JobScheduler: Added jobs for time 1638792441000 ms
21/12/06 17:37:21 INFO PythonRunner: Times: total = 2091, boot = 22, init = 97, finish = 1972
21/12/06 17:37:21 INFO MemoryStore: Block taskresult_2 stored as bytes in memory (estimated size 3.6 MiB, free 321.6 MiB)
21/12/06 17:37:21 INFO BlockManagerInfo: Added taskresult_2 in memory on 192.168.0.148:33235 (size: 3.6 MiB, free: 321.7 MiB)
21/12/06 17:37:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 3792067 bytes result sent via BlockManager)
21/12/06 17:37:21 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (192.168.0.148, executor driver, partition 1, PROCESS_LOCAL, 14321692 bytes) taskResourceAssignments Map()
21/12/06 17:37:21 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
21/12/06 17:37:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2902 ms on 192.168.0.148 (executor driver) (1/2)
21/12/06 17:37:21 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 40653
21/12/06 17:37:21 INFO BlockManagerInfo: Removed taskresult_2 on 192.168.0.148:33235 in memory (size: 3.6 MiB, free: 325.3 MiB)
21/12/06 17:37:22 INFO JobScheduler: Added jobs for time 1638792442000 ms
21/12/06 17:37:22 INFO PythonRunner: Times: total = 235, boot = -1202, init = 1204, finish = 233
21/12/06 17:37:22 INFO PythonRunner: Times: total = 1246, boot = -118, init = 150, finish = 1214
21/12/06 17:37:22 INFO MemoryStore: Block taskresult_3 stored as bytes in memory (estimated size 3.5 MiB, free 321.6 MiB)
21/12/06 17:37:22 INFO BlockManagerInfo: Added taskresult_3 in memory on 192.168.0.148:33235 (size: 3.5 MiB, free: 321.7 MiB)
21/12/06 17:37:22 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 3712874 bytes result sent via BlockManager)
21/12/06 17:37:22 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 1366 ms on 192.168.0.148 (executor driver) (2/2)
21/12/06 17:37:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/12/06 17:37:22 INFO DAGScheduler: ResultStage 2 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 4.239 s
21/12/06 17:37:22 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/12/06 17:37:22 INFO DAGScheduler: Job 6 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 4.245225 s
21/12/06 17:37:22 INFO BlockManagerInfo: Removed taskresult_3 on 192.168.0.148:33235 in memory (size: 3.5 MiB, free: 325.3 MiB)
21/12/06 17:37:22 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.148:33235 in memory (size: 11.4 KiB, free: 325.3 MiB)
21/12/06 17:37:23 INFO JobScheduler: Added jobs for time 1638792443000 ms
21/12/06 17:37:24 INFO JobScheduler: Added jobs for time 1638792444000 ms
21/12/06 17:37:24 INFO CodeGenerator: Code generated in 18.73419 ms
21/12/06 17:37:24 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:24 INFO DAGScheduler: Got job 7 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/12/06 17:37:24 INFO DAGScheduler: Final stage: ResultStage 3 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:24 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:24 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:24 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[33] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/12/06 17:37:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 325.2 MiB)
21/12/06 17:37:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 325.2 MiB)
21/12/06 17:37:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.148:33235 (size: 5.8 KiB, free: 325.3 MiB)
21/12/06 17:37:24 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[33] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/12/06 17:37:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks resource profile 0
21/12/06 17:37:24 WARN TaskSetManager: Stage 3 contains a task of very large size (14004 KiB). The maximum recommended task size is 1000 KiB.
21/12/06 17:37:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 14341093 bytes) taskResourceAssignments Map()
21/12/06 17:37:24 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
21/12/06 17:37:24 INFO PythonRunner: Times: total = 209, boot = -2942, init = 2951, finish = 200
21/12/06 17:37:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 526310 bytes result sent to driver
21/12/06 17:37:24 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5) (192.168.0.148, executor driver, partition 1, PROCESS_LOCAL, 14321692 bytes) taskResourceAssignments Map()
21/12/06 17:37:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 396 ms on 192.168.0.148 (executor driver) (1/2)
21/12/06 17:37:24 INFO Executor: Running task 1.0 in stage 3.0 (TID 5)
21/12/06 17:37:25 INFO JobScheduler: Added jobs for time 1638792445000 ms
21/12/06 17:37:25 INFO PythonRunner: Times: total = 130, boot = -2315, init = 2316, finish = 129
21/12/06 17:37:25 INFO Executor: Finished task 1.0 in stage 3.0 (TID 5). 541932 bytes result sent to driver
21/12/06 17:37:25 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 211 ms on 192.168.0.148 (executor driver) (2/2)
21/12/06 17:37:25 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/12/06 17:37:25 INFO DAGScheduler: ResultStage 3 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.608 s
21/12/06 17:37:25 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/12/06 17:37:25 INFO DAGScheduler: Job 7 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.615914 s
21/12/06 17:37:25 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.148:33235 in memory (size: 5.8 KiB, free: 325.3 MiB)
21/12/06 17:37:25 INFO MemoryStore: Block input-0-1638792445600 stored as values in memory (estimated size 54.5 MiB, free 270.7 MiB)
21/12/06 17:37:25 INFO BlockManagerInfo: Added input-0-1638792445600 in memory on 192.168.0.148:33235 (size: 54.5 MiB, free: 270.8 MiB)
21/12/06 17:37:25 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/06 17:37:25 WARN BlockManager: Block input-0-1638792445600 replicated to only 0 peer(s) instead of 1 peers
21/12/06 17:37:25 INFO BlockGenerator: Pushed block input-0-1638792445600
21/12/06 17:37:26 INFO JobScheduler: Added jobs for time 1638792446000 ms
21/12/06 17:37:26 INFO JobScheduler: Finished job streaming job 1638792433000 ms.0 from job set of time 1638792433000 ms
21/12/06 17:37:26 INFO JobScheduler: Total delay: 13.272 s for time 1638792433000 ms (execution: 13.267 s)
21/12/06 17:37:26 INFO BlockRDD: Removing RDD 4 from persistence list
21/12/06 17:37:26 INFO JobScheduler: Starting job streaming job 1638792434000 ms.0 from job set of time 1638792434000 ms
21/12/06 17:37:26 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[4] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792433000 ms
21/12/06 17:37:26 INFO ReceivedBlockTracker: Deleting batches: 1638792431000 ms
21/12/06 17:37:26 INFO BlockManager: Removing RDD 4
21/12/06 17:37:26 INFO InputInfoTracker: remove old batch metadata: 1638792431000 ms
21/12/06 17:37:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:26 INFO DAGScheduler: Job 8 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000123 s
21/12/06 17:37:26 INFO JobScheduler: Finished job streaming job 1638792434000 ms.0 from job set of time 1638792434000 ms
21/12/06 17:37:26 INFO JobScheduler: Total delay: 12.286 s for time 1638792434000 ms (execution: 0.014 s)
21/12/06 17:37:26 INFO BlockRDD: Removing RDD 5 from persistence list
21/12/06 17:37:26 INFO JobScheduler: Starting job streaming job 1638792435000 ms.0 from job set of time 1638792435000 ms
21/12/06 17:37:26 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[5] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792434000 ms
21/12/06 17:37:26 INFO BlockManager: Removing RDD 5
21/12/06 17:37:26 INFO ReceivedBlockTracker: Deleting batches: 1638792432000 ms
21/12/06 17:37:26 INFO InputInfoTracker: remove old batch metadata: 1638792432000 ms
21/12/06 17:37:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:26 INFO DAGScheduler: Job 9 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000116 s
21/12/06 17:37:26 INFO BlockManagerInfo: Removed input-0-1638792432000 on 192.168.0.148:33235 in memory (size: 54.5 MiB, free: 325.3 MiB)
21/12/06 17:37:26 INFO JobScheduler: Finished job streaming job 1638792435000 ms.0 from job set of time 1638792435000 ms
21/12/06 17:37:26 INFO JobScheduler: Total delay: 11.303 s for time 1638792435000 ms (execution: 0.016 s)
21/12/06 17:37:26 INFO BlockRDD: Removing RDD 6 from persistence list
21/12/06 17:37:26 INFO JobScheduler: Starting job streaming job 1638792436000 ms.0 from job set of time 1638792436000 ms
21/12/06 17:37:26 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[6] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792435000 ms
21/12/06 17:37:26 INFO ReceivedBlockTracker: Deleting batches: 1638792433000 ms
21/12/06 17:37:26 INFO InputInfoTracker: remove old batch metadata: 1638792433000 ms
21/12/06 17:37:26 INFO BlockManager: Removing RDD 6
21/12/06 17:37:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:26 INFO DAGScheduler: Job 10 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000117 s
21/12/06 17:37:26 INFO JobScheduler: Finished job streaming job 1638792436000 ms.0 from job set of time 1638792436000 ms
21/12/06 17:37:26 INFO JobScheduler: Total delay: 10.324 s for time 1638792436000 ms (execution: 0.021 s)
21/12/06 17:37:26 INFO BlockRDD: Removing RDD 7 from persistence list
21/12/06 17:37:26 INFO JobScheduler: Starting job streaming job 1638792437000 ms.0 from job set of time 1638792437000 ms
21/12/06 17:37:26 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[7] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792436000 ms
21/12/06 17:37:26 INFO BlockManager: Removing RDD 7
21/12/06 17:37:26 INFO ReceivedBlockTracker: Deleting batches: 1638792434000 ms
21/12/06 17:37:26 INFO InputInfoTracker: remove old batch metadata: 1638792434000 ms
21/12/06 17:37:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:26 INFO DAGScheduler: Job 11 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000132 s
21/12/06 17:37:26 INFO JobScheduler: Finished job streaming job 1638792437000 ms.0 from job set of time 1638792437000 ms
21/12/06 17:37:26 INFO JobScheduler: Total delay: 9.337 s for time 1638792437000 ms (execution: 0.013 s)
21/12/06 17:37:26 INFO BlockRDD: Removing RDD 8 from persistence list
21/12/06 17:37:26 INFO JobScheduler: Starting job streaming job 1638792438000 ms.0 from job set of time 1638792438000 ms
21/12/06 17:37:26 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[8] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792437000 ms
21/12/06 17:37:26 INFO ReceivedBlockTracker: Deleting batches: 1638792435000 ms
21/12/06 17:37:26 INFO InputInfoTracker: remove old batch metadata: 1638792435000 ms
21/12/06 17:37:26 INFO BlockManager: Removing RDD 8
21/12/06 17:37:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:26 INFO DAGScheduler: Job 12 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000120 s
21/12/06 17:37:26 INFO JobScheduler: Finished job streaming job 1638792438000 ms.0 from job set of time 1638792438000 ms
21/12/06 17:37:26 INFO JobScheduler: Total delay: 8.348 s for time 1638792438000 ms (execution: 0.011 s)
21/12/06 17:37:26 INFO BlockRDD: Removing RDD 14 from persistence list
21/12/06 17:37:26 INFO JobScheduler: Starting job streaming job 1638792439000 ms.0 from job set of time 1638792439000 ms
21/12/06 17:37:26 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[14] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792438000 ms
21/12/06 17:37:26 INFO BlockManager: Removing RDD 14
21/12/06 17:37:26 INFO ReceivedBlockTracker: Deleting batches: 1638792436000 ms
21/12/06 17:37:26 INFO InputInfoTracker: remove old batch metadata: 1638792436000 ms
21/12/06 17:37:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:26 INFO DAGScheduler: Job 13 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000121 s
21/12/06 17:37:26 INFO JobScheduler: Finished job streaming job 1638792439000 ms.0 from job set of time 1638792439000 ms
21/12/06 17:37:26 INFO JobScheduler: Total delay: 7.360 s for time 1638792439000 ms (execution: 0.012 s)
21/12/06 17:37:26 INFO BlockRDD: Removing RDD 15 from persistence list
21/12/06 17:37:26 INFO JobScheduler: Starting job streaming job 1638792440000 ms.0 from job set of time 1638792440000 ms
21/12/06 17:37:26 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[15] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792439000 ms
21/12/06 17:37:26 INFO ReceivedBlockTracker: Deleting batches: 1638792437000 ms
21/12/06 17:37:26 INFO InputInfoTracker: remove old batch metadata: 1638792437000 ms
21/12/06 17:37:26 INFO BlockManager: Removing RDD 15
21/12/06 17:37:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:26 INFO DAGScheduler: Got job 14 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/06 17:37:26 INFO DAGScheduler: Final stage: ResultStage 4 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:26 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:26 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:26 INFO DAGScheduler: Submitting ResultStage 4 (BlockRDD[27] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/06 17:37:26 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 1968.0 B, free 325.2 MiB)
21/12/06 17:37:26 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1210.0 B, free 325.2 MiB)
21/12/06 17:37:26 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.148:33235 (size: 1210.0 B, free: 325.3 MiB)
21/12/06 17:37:26 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (BlockRDD[27] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/06 17:37:26 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
21/12/06 17:37:26 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/06 17:37:26 INFO Executor: Running task 0.0 in stage 4.0 (TID 6)
21/12/06 17:37:26 INFO BlockManager: Found block input-0-1638792439000 locally
21/12/06 17:37:26 INFO MemoryStore: Block taskresult_6 stored as bytes in memory (estimated size 54.8 MiB, free 270.4 MiB)
21/12/06 17:37:26 INFO BlockManagerInfo: Added taskresult_6 in memory on 192.168.0.148:33235 (size: 54.8 MiB, free: 270.4 MiB)
21/12/06 17:37:26 INFO Executor: Finished task 0.0 in stage 4.0 (TID 6). 57497369 bytes result sent via BlockManager)
21/12/06 17:37:27 INFO JobScheduler: Added jobs for time 1638792447000 ms
21/12/06 17:37:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 657 ms on 192.168.0.148 (executor driver) (1/1)
21/12/06 17:37:27 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/12/06 17:37:27 INFO DAGScheduler: ResultStage 4 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.662 s
21/12/06 17:37:27 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
21/12/06 17:37:27 INFO DAGScheduler: Job 14 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.664415 s
21/12/06 17:37:27 INFO BlockManagerInfo: Removed taskresult_6 on 192.168.0.148:33235 in memory (size: 54.8 MiB, free: 325.3 MiB)
21/12/06 17:37:27 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.148:33235 in memory (size: 1210.0 B, free: 325.3 MiB)
21/12/06 17:37:28 INFO JobScheduler: Added jobs for time 1638792448000 ms
21/12/06 17:37:29 INFO JobScheduler: Added jobs for time 1638792449000 ms
21/12/06 17:37:29 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:29 INFO DAGScheduler: Got job 15 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/12/06 17:37:29 INFO DAGScheduler: Final stage: ResultStage 5 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:29 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:29 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:29 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[53] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/12/06 17:37:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.0 KiB, free 325.2 MiB)
21/12/06 17:37:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 325.2 MiB)
21/12/06 17:37:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.148:33235 (size: 11.4 KiB, free: 325.3 MiB)
21/12/06 17:37:29 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[53] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/12/06 17:37:29 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks resource profile 0
21/12/06 17:37:29 WARN TaskSetManager: Stage 5 contains a task of very large size (14044 KiB). The maximum recommended task size is 1000 KiB.
21/12/06 17:37:29 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 14381252 bytes) taskResourceAssignments Map()
21/12/06 17:37:29 INFO Executor: Running task 0.0 in stage 5.0 (TID 7)
21/12/06 17:37:30 INFO JobScheduler: Added jobs for time 1638792450000 ms
21/12/06 17:37:30 INFO PythonRunner: Times: total = 354, boot = -4707, init = 4708, finish = 353
21/12/06 17:37:30 INFO PythonRunner: Times: total = 1226, boot = -4402, init = 4445, finish = 1183
21/12/06 17:37:30 INFO MemoryStore: Block taskresult_7 stored as bytes in memory (estimated size 3.6 MiB, free 321.5 MiB)
21/12/06 17:37:30 INFO BlockManagerInfo: Added taskresult_7 in memory on 192.168.0.148:33235 (size: 3.6 MiB, free: 321.7 MiB)
21/12/06 17:37:30 INFO Executor: Finished task 0.0 in stage 5.0 (TID 7). 3786225 bytes result sent via BlockManager)
21/12/06 17:37:30 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 8) (192.168.0.148, executor driver, partition 1, PROCESS_LOCAL, 14341868 bytes) taskResourceAssignments Map()
21/12/06 17:37:30 INFO Executor: Running task 1.0 in stage 5.0 (TID 8)
21/12/06 17:37:30 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 1299 ms on 192.168.0.148 (executor driver) (1/2)
21/12/06 17:37:30 INFO BlockManagerInfo: Removed taskresult_7 on 192.168.0.148:33235 in memory (size: 3.6 MiB, free: 325.3 MiB)
21/12/06 17:37:31 INFO JobScheduler: Added jobs for time 1638792451000 ms
21/12/06 17:37:31 INFO PythonRunner: Times: total = 206, boot = -932, init = 934, finish = 204
21/12/06 17:37:31 INFO PythonRunner: Times: total = 1124, boot = -60, init = 76, finish = 1108
21/12/06 17:37:31 INFO MemoryStore: Block taskresult_8 stored as bytes in memory (estimated size 3.6 MiB, free 321.6 MiB)
21/12/06 17:37:31 INFO BlockManagerInfo: Added taskresult_8 in memory on 192.168.0.148:33235 (size: 3.6 MiB, free: 321.7 MiB)
21/12/06 17:37:31 INFO Executor: Finished task 1.0 in stage 5.0 (TID 8). 3768148 bytes result sent via BlockManager)
21/12/06 17:37:31 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 8) in 1236 ms on 192.168.0.148 (executor driver) (2/2)
21/12/06 17:37:31 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/12/06 17:37:31 INFO DAGScheduler: ResultStage 5 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 2.510 s
21/12/06 17:37:31 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/12/06 17:37:31 INFO BlockManagerInfo: Removed taskresult_8 on 192.168.0.148:33235 in memory (size: 3.6 MiB, free: 325.3 MiB)
21/12/06 17:37:31 INFO DAGScheduler: Job 15 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 2.528575 s
21/12/06 17:37:32 INFO JobScheduler: Added jobs for time 1638792452000 ms
21/12/06 17:37:32 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.0.148:33235 in memory (size: 11.4 KiB, free: 325.3 MiB)
21/12/06 17:37:32 INFO MemoryStore: Block input-0-1638792452200 stored as values in memory (estimated size 54.3 MiB, free 270.8 MiB)
21/12/06 17:37:32 INFO BlockManagerInfo: Added input-0-1638792452200 in memory on 192.168.0.148:33235 (size: 54.3 MiB, free: 270.9 MiB)
21/12/06 17:37:32 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
21/12/06 17:37:32 WARN BlockManager: Block input-0-1638792452200 replicated to only 0 peer(s) instead of 1 peers
21/12/06 17:37:32 INFO BlockGenerator: Pushed block input-0-1638792452200
21/12/06 17:37:33 INFO JobScheduler: Added jobs for time 1638792453000 ms
21/12/06 17:37:33 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:33 INFO DAGScheduler: Got job 16 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/12/06 17:37:33 INFO DAGScheduler: Final stage: ResultStage 6 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:33 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:33 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:33 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[59] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/12/06 17:37:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 270.8 MiB)
21/12/06 17:37:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 270.8 MiB)
21/12/06 17:37:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.0.148:33235 (size: 5.8 KiB, free: 270.9 MiB)
21/12/06 17:37:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[59] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/12/06 17:37:33 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
21/12/06 17:37:33 WARN TaskSetManager: Stage 6 contains a task of very large size (14044 KiB). The maximum recommended task size is 1000 KiB.
21/12/06 17:37:33 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 9) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 14381252 bytes) taskResourceAssignments Map()
21/12/06 17:37:33 INFO Executor: Running task 0.0 in stage 6.0 (TID 9)
21/12/06 17:37:33 INFO PythonRunner: Times: total = 133, boot = -2702, init = 2704, finish = 131
21/12/06 17:37:33 INFO Executor: Finished task 0.0 in stage 6.0 (TID 9). 558235 bytes result sent to driver
21/12/06 17:37:33 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 10) (192.168.0.148, executor driver, partition 1, PROCESS_LOCAL, 14341868 bytes) taskResourceAssignments Map()
21/12/06 17:37:33 INFO Executor: Running task 1.0 in stage 6.0 (TID 10)
21/12/06 17:37:33 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 9) in 263 ms on 192.168.0.148 (executor driver) (1/2)
21/12/06 17:37:34 INFO JobScheduler: Added jobs for time 1638792454000 ms
21/12/06 17:37:34 INFO PythonRunner: Times: total = 151, boot = -2049, init = 2050, finish = 150
21/12/06 17:37:34 INFO Executor: Finished task 1.0 in stage 6.0 (TID 10). 557448 bytes result sent to driver
21/12/06 17:37:34 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 10) in 283 ms on 192.168.0.148 (executor driver) (2/2)
21/12/06 17:37:34 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/12/06 17:37:34 INFO DAGScheduler: ResultStage 6 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.586 s
21/12/06 17:37:34 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/12/06 17:37:34 INFO DAGScheduler: Job 16 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.588313 s
21/12/06 17:37:34 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.0.148:33235 in memory (size: 5.8 KiB, free: 270.9 MiB)
21/12/06 17:37:35 INFO JobScheduler: Added jobs for time 1638792455000 ms
21/12/06 17:37:35 INFO JobScheduler: Finished job streaming job 1638792440000 ms.0 from job set of time 1638792440000 ms
21/12/06 17:37:35 INFO JobScheduler: Total delay: 15.413 s for time 1638792440000 ms (execution: 9.052 s)
21/12/06 17:37:35 INFO BlockRDD: Removing RDD 26 from persistence list
21/12/06 17:37:35 INFO JobScheduler: Starting job streaming job 1638792441000 ms.0 from job set of time 1638792441000 ms
21/12/06 17:37:35 INFO BlockManager: Removing RDD 26
21/12/06 17:37:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[26] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792440000 ms
21/12/06 17:37:35 INFO ReceivedBlockTracker: Deleting batches: 1638792438000 ms
21/12/06 17:37:35 INFO InputInfoTracker: remove old batch metadata: 1638792438000 ms
21/12/06 17:37:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:35 INFO DAGScheduler: Job 17 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000606 s
21/12/06 17:37:35 INFO JobScheduler: Finished job streaming job 1638792441000 ms.0 from job set of time 1638792441000 ms
21/12/06 17:37:35 INFO JobScheduler: Total delay: 14.431 s for time 1638792441000 ms (execution: 0.017 s)
21/12/06 17:37:35 INFO BlockRDD: Removing RDD 27 from persistence list
21/12/06 17:37:35 INFO JobScheduler: Starting job streaming job 1638792442000 ms.0 from job set of time 1638792442000 ms
21/12/06 17:37:35 INFO BlockManager: Removing RDD 27
21/12/06 17:37:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[27] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792441000 ms
21/12/06 17:37:35 INFO ReceivedBlockTracker: Deleting batches: 1638792439000 ms
21/12/06 17:37:35 INFO InputInfoTracker: remove old batch metadata: 1638792439000 ms
21/12/06 17:37:35 INFO BlockManagerInfo: Removed input-0-1638792439000 on 192.168.0.148:33235 in memory (size: 54.6 MiB, free: 325.5 MiB)
21/12/06 17:37:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:35 INFO DAGScheduler: Job 18 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000448 s
21/12/06 17:37:35 INFO JobScheduler: Finished job streaming job 1638792442000 ms.0 from job set of time 1638792442000 ms
21/12/06 17:37:35 INFO JobScheduler: Total delay: 13.453 s for time 1638792442000 ms (execution: 0.022 s)
21/12/06 17:37:35 INFO JobScheduler: Starting job streaming job 1638792443000 ms.0 from job set of time 1638792443000 ms
21/12/06 17:37:35 INFO BlockRDD: Removing RDD 28 from persistence list
21/12/06 17:37:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[28] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792442000 ms
21/12/06 17:37:35 INFO BlockManager: Removing RDD 28
21/12/06 17:37:35 INFO ReceivedBlockTracker: Deleting batches: 1638792440000 ms
21/12/06 17:37:35 INFO InputInfoTracker: remove old batch metadata: 1638792440000 ms
21/12/06 17:37:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:35 INFO DAGScheduler: Job 19 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000114 s
21/12/06 17:37:35 INFO JobScheduler: Finished job streaming job 1638792443000 ms.0 from job set of time 1638792443000 ms
21/12/06 17:37:35 INFO JobScheduler: Total delay: 12.475 s for time 1638792443000 ms (execution: 0.022 s)
21/12/06 17:37:35 INFO JobScheduler: Starting job streaming job 1638792444000 ms.0 from job set of time 1638792444000 ms
21/12/06 17:37:35 INFO BlockRDD: Removing RDD 29 from persistence list
21/12/06 17:37:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[29] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792443000 ms
21/12/06 17:37:35 INFO BlockManager: Removing RDD 29
21/12/06 17:37:35 INFO ReceivedBlockTracker: Deleting batches: 1638792441000 ms
21/12/06 17:37:35 INFO InputInfoTracker: remove old batch metadata: 1638792441000 ms
21/12/06 17:37:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:35 INFO DAGScheduler: Job 20 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000421 s
21/12/06 17:37:35 INFO JobScheduler: Finished job streaming job 1638792444000 ms.0 from job set of time 1638792444000 ms
21/12/06 17:37:35 INFO JobScheduler: Total delay: 11.494 s for time 1638792444000 ms (execution: 0.019 s)
21/12/06 17:37:35 INFO JobScheduler: Starting job streaming job 1638792445000 ms.0 from job set of time 1638792445000 ms
21/12/06 17:37:35 INFO BlockRDD: Removing RDD 30 from persistence list
21/12/06 17:37:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[30] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792444000 ms
21/12/06 17:37:35 INFO ReceivedBlockTracker: Deleting batches: 1638792442000 ms
21/12/06 17:37:35 INFO BlockManager: Removing RDD 30
21/12/06 17:37:35 INFO InputInfoTracker: remove old batch metadata: 1638792442000 ms
21/12/06 17:37:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:35 INFO DAGScheduler: Job 21 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000463 s
21/12/06 17:37:35 INFO JobScheduler: Finished job streaming job 1638792445000 ms.0 from job set of time 1638792445000 ms
21/12/06 17:37:35 INFO JobScheduler: Total delay: 10.513 s for time 1638792445000 ms (execution: 0.018 s)
21/12/06 17:37:35 INFO BlockRDD: Removing RDD 31 from persistence list
21/12/06 17:37:35 INFO JobScheduler: Starting job streaming job 1638792446000 ms.0 from job set of time 1638792446000 ms
21/12/06 17:37:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[31] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792445000 ms
21/12/06 17:37:35 INFO BlockManager: Removing RDD 31
21/12/06 17:37:35 INFO ReceivedBlockTracker: Deleting batches: 1638792443000 ms
21/12/06 17:37:35 INFO InputInfoTracker: remove old batch metadata: 1638792443000 ms
21/12/06 17:37:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:35 INFO DAGScheduler: Got job 22 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/06 17:37:35 INFO DAGScheduler: Final stage: ResultStage 7 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:35 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:35 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:35 INFO DAGScheduler: Submitting ResultStage 7 (BlockRDD[35] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/06 17:37:35 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1968.0 B, free 325.4 MiB)
21/12/06 17:37:35 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1210.0 B, free 325.4 MiB)
21/12/06 17:37:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.0.148:33235 (size: 1210.0 B, free: 325.5 MiB)
21/12/06 17:37:35 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (BlockRDD[35] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/06 17:37:35 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
21/12/06 17:37:35 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 11) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/06 17:37:35 INFO Executor: Running task 0.0 in stage 7.0 (TID 11)
21/12/06 17:37:35 INFO BlockManager: Found block input-0-1638792445600 locally
21/12/06 17:37:35 INFO MemoryStore: Block taskresult_11 stored as bytes in memory (estimated size 54.8 MiB, free 270.6 MiB)
21/12/06 17:37:35 INFO BlockManagerInfo: Added taskresult_11 in memory on 192.168.0.148:33235 (size: 54.8 MiB, free: 270.7 MiB)
21/12/06 17:37:35 INFO Executor: Finished task 0.0 in stage 7.0 (TID 11). 57460915 bytes result sent via BlockManager)
21/12/06 17:37:36 INFO JobScheduler: Added jobs for time 1638792456000 ms
21/12/06 17:37:36 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 11) in 677 ms on 192.168.0.148 (executor driver) (1/1)
21/12/06 17:37:36 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/12/06 17:37:36 INFO DAGScheduler: ResultStage 7 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.690 s
21/12/06 17:37:36 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/12/06 17:37:36 INFO DAGScheduler: Job 22 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.693443 s
21/12/06 17:37:36 INFO BlockManagerInfo: Removed taskresult_11 on 192.168.0.148:33235 in memory (size: 54.8 MiB, free: 325.5 MiB)
21/12/06 17:37:37 INFO JobScheduler: Added jobs for time 1638792457000 ms
21/12/06 17:37:38 INFO JobScheduler: Added jobs for time 1638792458000 ms
21/12/06 17:37:38 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:38 INFO DAGScheduler: Got job 23 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/12/06 17:37:38 INFO DAGScheduler: Final stage: ResultStage 8 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:38 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:38 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:38 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[79] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/12/06 17:37:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 28.0 KiB, free 325.4 MiB)
21/12/06 17:37:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 325.4 MiB)
21/12/06 17:37:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.0.148:33235 (size: 11.4 KiB, free: 325.5 MiB)
21/12/06 17:37:38 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.0.148:33235 in memory (size: 1210.0 B, free: 325.5 MiB)
21/12/06 17:37:38 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[79] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/12/06 17:37:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks resource profile 0
21/12/06 17:37:38 WARN TaskSetManager: Stage 8 contains a task of very large size (14084 KiB). The maximum recommended task size is 1000 KiB.
21/12/06 17:37:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 12) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 14422973 bytes) taskResourceAssignments Map()
21/12/06 17:37:38 INFO Executor: Running task 0.0 in stage 8.0 (TID 12)
21/12/06 17:37:39 INFO JobScheduler: Added jobs for time 1638792459000 ms
21/12/06 17:37:39 INFO PythonRunner: Times: total = 290, boot = -4868, init = 4875, finish = 283
21/12/06 17:37:39 INFO PythonRunner: Times: total = 1163, boot = -4606, init = 4618, finish = 1151
21/12/06 17:37:39 INFO MemoryStore: Block taskresult_12 stored as bytes in memory (estimated size 3.7 MiB, free 321.6 MiB)
21/12/06 17:37:39 INFO BlockManagerInfo: Added taskresult_12 in memory on 192.168.0.148:33235 (size: 3.7 MiB, free: 321.7 MiB)
21/12/06 17:37:39 INFO Executor: Finished task 0.0 in stage 8.0 (TID 12). 3911755 bytes result sent via BlockManager)
21/12/06 17:37:39 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 13) (192.168.0.148, executor driver, partition 1, PROCESS_LOCAL, 14262109 bytes) taskResourceAssignments Map()
21/12/06 17:37:39 INFO Executor: Running task 1.0 in stage 8.0 (TID 13)
21/12/06 17:37:39 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 12) in 1259 ms on 192.168.0.148 (executor driver) (1/2)
21/12/06 17:37:39 INFO BlockManagerInfo: Removed taskresult_12 on 192.168.0.148:33235 in memory (size: 3.7 MiB, free: 325.5 MiB)
21/12/06 17:37:40 INFO JobScheduler: Added jobs for time 1638792460000 ms
21/12/06 17:37:40 INFO PythonRunner: Times: total = 243, boot = -947, init = 950, finish = 240
21/12/06 17:37:41 INFO JobScheduler: Added jobs for time 1638792461000 ms
21/12/06 17:37:41 INFO PythonRunner: Times: total = 1199, boot = -63, init = 101, finish = 1161
21/12/06 17:37:41 INFO MemoryStore: Block taskresult_13 stored as bytes in memory (estimated size 3.8 MiB, free 321.6 MiB)
21/12/06 17:37:41 INFO BlockManagerInfo: Added taskresult_13 in memory on 192.168.0.148:33235 (size: 3.8 MiB, free: 321.7 MiB)
21/12/06 17:37:41 INFO Executor: Finished task 1.0 in stage 8.0 (TID 13). 3975418 bytes result sent via BlockManager)
21/12/06 17:37:41 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 13) in 1283 ms on 192.168.0.148 (executor driver) (2/2)
21/12/06 17:37:41 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/12/06 17:37:41 INFO DAGScheduler: ResultStage 8 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 2.540 s
21/12/06 17:37:41 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
21/12/06 17:37:41 INFO DAGScheduler: Job 23 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 2.543966 s
21/12/06 17:37:41 INFO BlockManagerInfo: Removed taskresult_13 on 192.168.0.148:33235 in memory (size: 3.8 MiB, free: 325.5 MiB)
21/12/06 17:37:41 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.0.148:33235 in memory (size: 11.4 KiB, free: 325.5 MiB)
21/12/06 17:37:42 INFO JobScheduler: Added jobs for time 1638792462000 ms
21/12/06 17:37:42 INFO SocketReceiver: Closed socket to localhost:6100
21/12/06 17:37:42 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Socket data stream had no more data
21/12/06 17:37:42 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Socket data stream had no more data: 
21/12/06 17:37:42 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:37:42 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:37:42 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Socket data stream had no more data
21/12/06 17:37:42 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:37:42 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:42 INFO DAGScheduler: Got job 24 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/12/06 17:37:42 INFO DAGScheduler: Final stage: ResultStage 9 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:42 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:42 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:42 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[85] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/12/06 17:37:42 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 325.4 MiB)
21/12/06 17:37:42 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 325.4 MiB)
21/12/06 17:37:42 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.0.148:33235 (size: 5.8 KiB, free: 325.5 MiB)
21/12/06 17:37:42 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[85] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/12/06 17:37:42 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0
21/12/06 17:37:42 WARN TaskSetManager: Stage 9 contains a task of very large size (14084 KiB). The maximum recommended task size is 1000 KiB.
21/12/06 17:37:42 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 14) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 14422973 bytes) taskResourceAssignments Map()
21/12/06 17:37:42 INFO Executor: Running task 0.0 in stage 9.0 (TID 14)
21/12/06 17:37:43 INFO JobScheduler: Added jobs for time 1638792463000 ms
21/12/06 17:37:43 INFO PythonRunner: Times: total = 165, boot = -2609, init = 2611, finish = 163
21/12/06 17:37:43 INFO Executor: Finished task 0.0 in stage 9.0 (TID 14). 565838 bytes result sent to driver
21/12/06 17:37:43 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 15) (192.168.0.148, executor driver, partition 1, PROCESS_LOCAL, 14262109 bytes) taskResourceAssignments Map()
21/12/06 17:37:43 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 14) in 281 ms on 192.168.0.148 (executor driver) (1/2)
21/12/06 17:37:43 INFO Executor: Running task 1.0 in stage 9.0 (TID 15)
21/12/06 17:37:43 INFO PythonRunner: Times: total = 128, boot = -1934, init = 1938, finish = 124
21/12/06 17:37:43 INFO Executor: Finished task 1.0 in stage 9.0 (TID 15). 571157 bytes result sent to driver
21/12/06 17:37:43 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 15) in 225 ms on 192.168.0.148 (executor driver) (2/2)
21/12/06 17:37:43 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/12/06 17:37:43 INFO DAGScheduler: ResultStage 9 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.500 s
21/12/06 17:37:43 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
21/12/06 17:37:43 INFO DAGScheduler: Job 24 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.503482 s
21/12/06 17:37:44 INFO JobScheduler: Added jobs for time 1638792464000 ms
21/12/06 17:37:44 INFO JobScheduler: Finished job streaming job 1638792446000 ms.0 from job set of time 1638792446000 ms
21/12/06 17:37:44 INFO JobScheduler: Total delay: 18.262 s for time 1638792446000 ms (execution: 8.749 s)
21/12/06 17:37:44 INFO JobScheduler: Starting job streaming job 1638792447000 ms.0 from job set of time 1638792447000 ms
21/12/06 17:37:44 INFO BlockRDD: Removing RDD 34 from persistence list
21/12/06 17:37:44 INFO BlockManager: Removing RDD 34
21/12/06 17:37:44 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[34] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792446000 ms
21/12/06 17:37:44 INFO ReceivedBlockTracker: Deleting batches: 1638792444000 ms
21/12/06 17:37:44 INFO InputInfoTracker: remove old batch metadata: 1638792444000 ms
21/12/06 17:37:44 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:44 INFO DAGScheduler: Job 25 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000122 s
21/12/06 17:37:44 INFO JobScheduler: Finished job streaming job 1638792447000 ms.0 from job set of time 1638792447000 ms
21/12/06 17:37:44 INFO JobScheduler: Total delay: 17.277 s for time 1638792447000 ms (execution: 0.014 s)
21/12/06 17:37:44 INFO JobScheduler: Starting job streaming job 1638792448000 ms.0 from job set of time 1638792448000 ms
21/12/06 17:37:44 INFO BlockRDD: Removing RDD 35 from persistence list
21/12/06 17:37:44 INFO BlockManager: Removing RDD 35
21/12/06 17:37:44 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[35] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792447000 ms
21/12/06 17:37:44 INFO ReceivedBlockTracker: Deleting batches: 1638792445000 ms
21/12/06 17:37:44 INFO BlockManagerInfo: Removed input-0-1638792445600 on 192.168.0.148:33235 in memory (size: 54.5 MiB, free: 380.0 MiB)
21/12/06 17:37:44 INFO InputInfoTracker: remove old batch metadata: 1638792445000 ms
21/12/06 17:37:44 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:44 INFO DAGScheduler: Job 26 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000107 s
21/12/06 17:37:44 INFO JobScheduler: Finished job streaming job 1638792448000 ms.0 from job set of time 1638792448000 ms
21/12/06 17:37:44 INFO JobScheduler: Total delay: 16.295 s for time 1638792448000 ms (execution: 0.017 s)
21/12/06 17:37:44 INFO JobScheduler: Starting job streaming job 1638792449000 ms.0 from job set of time 1638792449000 ms
21/12/06 17:37:44 INFO BlockRDD: Removing RDD 36 from persistence list
21/12/06 17:37:44 INFO BlockManager: Removing RDD 36
21/12/06 17:37:44 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[36] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792448000 ms
21/12/06 17:37:44 INFO ReceivedBlockTracker: Deleting batches: 1638792446000 ms
21/12/06 17:37:44 INFO InputInfoTracker: remove old batch metadata: 1638792446000 ms
21/12/06 17:37:44 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:44 INFO DAGScheduler: Job 27 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000110 s
21/12/06 17:37:44 INFO JobScheduler: Finished job streaming job 1638792449000 ms.0 from job set of time 1638792449000 ms
21/12/06 17:37:44 INFO JobScheduler: Total delay: 15.307 s for time 1638792449000 ms (execution: 0.012 s)
21/12/06 17:37:44 INFO JobScheduler: Starting job streaming job 1638792450000 ms.0 from job set of time 1638792450000 ms
21/12/06 17:37:44 INFO BlockRDD: Removing RDD 37 from persistence list
21/12/06 17:37:44 INFO BlockManager: Removing RDD 37
21/12/06 17:37:44 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[37] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792449000 ms
21/12/06 17:37:44 INFO ReceivedBlockTracker: Deleting batches: 1638792447000 ms
21/12/06 17:37:44 INFO InputInfoTracker: remove old batch metadata: 1638792447000 ms
21/12/06 17:37:44 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:44 INFO DAGScheduler: Job 28 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000168 s
21/12/06 17:37:44 INFO JobScheduler: Finished job streaming job 1638792450000 ms.0 from job set of time 1638792450000 ms
21/12/06 17:37:44 INFO JobScheduler: Total delay: 14.319 s for time 1638792450000 ms (execution: 0.012 s)
21/12/06 17:37:44 INFO JobScheduler: Starting job streaming job 1638792451000 ms.0 from job set of time 1638792451000 ms
21/12/06 17:37:44 INFO BlockRDD: Removing RDD 38 from persistence list
21/12/06 17:37:44 INFO BlockManager: Removing RDD 38
21/12/06 17:37:44 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[38] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792450000 ms
21/12/06 17:37:44 INFO ReceivedBlockTracker: Deleting batches: 1638792448000 ms
21/12/06 17:37:44 INFO InputInfoTracker: remove old batch metadata: 1638792448000 ms
21/12/06 17:37:44 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:44 INFO DAGScheduler: Job 29 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000455 s
21/12/06 17:37:44 INFO JobScheduler: Finished job streaming job 1638792451000 ms.0 from job set of time 1638792451000 ms
21/12/06 17:37:44 INFO JobScheduler: Total delay: 13.331 s for time 1638792451000 ms (execution: 0.011 s)
21/12/06 17:37:44 INFO JobScheduler: Starting job streaming job 1638792452000 ms.0 from job set of time 1638792452000 ms
21/12/06 17:37:44 INFO BlockRDD: Removing RDD 54 from persistence list
21/12/06 17:37:44 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[54] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792451000 ms
21/12/06 17:37:44 INFO ReceivedBlockTracker: Deleting batches: 1638792449000 ms
21/12/06 17:37:44 INFO InputInfoTracker: remove old batch metadata: 1638792449000 ms
21/12/06 17:37:44 INFO BlockManager: Removing RDD 54
21/12/06 17:37:44 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:44 INFO DAGScheduler: Job 30 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000522 s
21/12/06 17:37:44 INFO JobScheduler: Finished job streaming job 1638792452000 ms.0 from job set of time 1638792452000 ms
21/12/06 17:37:44 INFO JobScheduler: Total delay: 12.342 s for time 1638792452000 ms (execution: 0.011 s)
21/12/06 17:37:44 INFO BlockRDD: Removing RDD 55 from persistence list
21/12/06 17:37:44 INFO JobScheduler: Starting job streaming job 1638792453000 ms.0 from job set of time 1638792453000 ms
21/12/06 17:37:44 INFO BlockManager: Removing RDD 55
21/12/06 17:37:44 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[55] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792452000 ms
21/12/06 17:37:44 INFO ReceivedBlockTracker: Deleting batches: 1638792450000 ms
21/12/06 17:37:44 INFO InputInfoTracker: remove old batch metadata: 1638792450000 ms
21/12/06 17:37:44 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:44 INFO DAGScheduler: Got job 31 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 1 output partitions
21/12/06 17:37:44 INFO DAGScheduler: Final stage: ResultStage 10 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:44 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:44 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:44 INFO DAGScheduler: Submitting ResultStage 10 (BlockRDD[57] at socketTextStream at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/06 17:37:44 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 1968.0 B, free 379.9 MiB)
21/12/06 17:37:44 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1210.0 B, free 379.9 MiB)
21/12/06 17:37:44 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.0.148:33235 (size: 1210.0 B, free: 380.0 MiB)
21/12/06 17:37:44 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (BlockRDD[57] at socketTextStream at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/06 17:37:44 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
21/12/06 17:37:44 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 16) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 4394 bytes) taskResourceAssignments Map()
21/12/06 17:37:44 INFO Executor: Running task 0.0 in stage 10.0 (TID 16)
21/12/06 17:37:44 INFO BlockManager: Found block input-0-1638792452200 locally
21/12/06 17:37:44 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:37:44 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:37:44 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:37:44 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:37:44 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:37:44 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:37:44 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:37:44 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:37:44 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:37:44 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:37:44 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:37:44 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:37:44 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.0.148:33235 in memory (size: 5.8 KiB, free: 380.0 MiB)
21/12/06 17:37:44 INFO MemoryStore: Block taskresult_16 stored as bytes in memory (estimated size 54.6 MiB, free 325.3 MiB)
21/12/06 17:37:44 INFO BlockManagerInfo: Added taskresult_16 in memory on 192.168.0.148:33235 (size: 54.6 MiB, free: 325.4 MiB)
21/12/06 17:37:44 INFO Executor: Finished task 0.0 in stage 10.0 (TID 16). 57267713 bytes result sent via BlockManager)
21/12/06 17:37:45 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 16) in 644 ms on 192.168.0.148 (executor driver) (1/1)
21/12/06 17:37:45 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/12/06 17:37:45 INFO DAGScheduler: ResultStage 10 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.648 s
21/12/06 17:37:45 INFO JobScheduler: Added jobs for time 1638792465000 ms
21/12/06 17:37:45 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
21/12/06 17:37:45 INFO BlockManagerInfo: Removed taskresult_16 on 192.168.0.148:33235 in memory (size: 54.6 MiB, free: 380.0 MiB)
21/12/06 17:37:45 INFO DAGScheduler: Job 31 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.650325 s
21/12/06 17:37:46 INFO JobScheduler: Added jobs for time 1638792466000 ms
21/12/06 17:37:46 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:37:46 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:37:46 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:37:46 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:37:46 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:37:46 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:37:46 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:37:46 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:37:46 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:37:46 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:37:46 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:37:46 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:37:47 INFO JobScheduler: Added jobs for time 1638792467000 ms
21/12/06 17:37:47 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:47 INFO DAGScheduler: Got job 32 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/12/06 17:37:47 INFO DAGScheduler: Final stage: ResultStage 11 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:47 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:47 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:47 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[105] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/12/06 17:37:47 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 28.0 KiB, free 379.9 MiB)
21/12/06 17:37:47 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 379.9 MiB)
21/12/06 17:37:47 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.0.148:33235 (size: 11.4 KiB, free: 380.0 MiB)
21/12/06 17:37:47 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[105] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/12/06 17:37:47 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks resource profile 0
21/12/06 17:37:47 WARN TaskSetManager: Stage 11 contains a task of very large size (13975 KiB). The maximum recommended task size is 1000 KiB.
21/12/06 17:37:47 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 17) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 14310885 bytes) taskResourceAssignments Map()
21/12/06 17:37:47 INFO Executor: Running task 0.0 in stage 11.0 (TID 17)
21/12/06 17:37:47 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.0.148:33235 in memory (size: 1210.0 B, free: 380.0 MiB)
21/12/06 17:37:48 INFO JobScheduler: Added jobs for time 1638792468000 ms
21/12/06 17:37:48 INFO PythonRunner: Times: total = 270, boot = -4429, init = 4430, finish = 269
21/12/06 17:37:48 INFO PythonRunner: Times: total = 1075, boot = -4186, init = 4215, finish = 1046
21/12/06 17:37:48 INFO MemoryStore: Block taskresult_17 stored as bytes in memory (estimated size 3.9 MiB, free 376.1 MiB)
21/12/06 17:37:48 INFO BlockManagerInfo: Added taskresult_17 in memory on 192.168.0.148:33235 (size: 3.9 MiB, free: 376.2 MiB)
21/12/06 17:37:48 INFO Executor: Finished task 0.0 in stage 11.0 (TID 17). 4039197 bytes result sent via BlockManager)
21/12/06 17:37:48 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 18) (192.168.0.148, executor driver, partition 1, PROCESS_LOCAL, 14185030 bytes) taskResourceAssignments Map()
21/12/06 17:37:48 INFO Executor: Running task 1.0 in stage 11.0 (TID 18)
21/12/06 17:37:48 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 17) in 1154 ms on 192.168.0.148 (executor driver) (1/2)
21/12/06 17:37:48 INFO BlockManagerInfo: Removed taskresult_17 on 192.168.0.148:33235 in memory (size: 3.9 MiB, free: 380.0 MiB)
21/12/06 17:37:48 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:37:48 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:37:48 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:37:48 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:37:48 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:37:48 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:37:48 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:37:48 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:37:48 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:37:48 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:37:48 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:37:48 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:37:49 INFO JobScheduler: Added jobs for time 1638792469000 ms
21/12/06 17:37:49 INFO PythonRunner: Times: total = 288, boot = -870, init = 884, finish = 274
21/12/06 17:37:49 INFO PythonRunner: Times: total = 1056, boot = -63, init = 100, finish = 1019
21/12/06 17:37:49 INFO MemoryStore: Block taskresult_18 stored as bytes in memory (estimated size 3.7 MiB, free 376.2 MiB)
21/12/06 17:37:49 INFO BlockManagerInfo: Added taskresult_18 in memory on 192.168.0.148:33235 (size: 3.7 MiB, free: 376.3 MiB)
21/12/06 17:37:49 INFO Executor: Finished task 1.0 in stage 11.0 (TID 18). 3892933 bytes result sent via BlockManager)
21/12/06 17:37:49 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 18) in 1131 ms on 192.168.0.148 (executor driver) (2/2)
21/12/06 17:37:49 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/12/06 17:37:49 INFO BlockManagerInfo: Removed taskresult_18 on 192.168.0.148:33235 in memory (size: 3.7 MiB, free: 380.0 MiB)
21/12/06 17:37:49 INFO DAGScheduler: ResultStage 11 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 2.277 s
21/12/06 17:37:49 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/12/06 17:37:49 INFO DAGScheduler: Job 32 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 2.280227 s
21/12/06 17:37:50 INFO JobScheduler: Added jobs for time 1638792470000 ms
21/12/06 17:37:50 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.0.148:33235 in memory (size: 11.4 KiB, free: 380.0 MiB)
21/12/06 17:37:50 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:37:50 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:37:50 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:37:50 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:37:50 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:37:50 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:37:50 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:37:50 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:37:50 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:37:50 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:37:50 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:37:50 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:37:51 INFO JobScheduler: Added jobs for time 1638792471000 ms
21/12/06 17:37:51 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:51 INFO DAGScheduler: Got job 33 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) with 2 output partitions
21/12/06 17:37:51 INFO DAGScheduler: Final stage: ResultStage 12 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442)
21/12/06 17:37:51 INFO DAGScheduler: Parents of final stage: List()
21/12/06 17:37:51 INFO DAGScheduler: Missing parents: List()
21/12/06 17:37:51 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[111] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442), which has no missing parents
21/12/06 17:37:51 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 11.0 KiB, free 379.9 MiB)
21/12/06 17:37:51 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 379.9 MiB)
21/12/06 17:37:51 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.0.148:33235 (size: 5.8 KiB, free: 380.0 MiB)
21/12/06 17:37:51 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1388
21/12/06 17:37:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[111] at call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) (first 15 tasks are for partitions Vector(0, 1))
21/12/06 17:37:51 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks resource profile 0
21/12/06 17:37:51 WARN TaskSetManager: Stage 12 contains a task of very large size (13975 KiB). The maximum recommended task size is 1000 KiB.
21/12/06 17:37:51 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 19) (192.168.0.148, executor driver, partition 0, PROCESS_LOCAL, 14310885 bytes) taskResourceAssignments Map()
21/12/06 17:37:51 INFO Executor: Running task 0.0 in stage 12.0 (TID 19)
21/12/06 17:37:51 INFO PythonRunner: Times: total = 136, boot = -2451, init = 2454, finish = 133
21/12/06 17:37:51 INFO Executor: Finished task 0.0 in stage 12.0 (TID 19). 569867 bytes result sent to driver
21/12/06 17:37:51 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 20) (192.168.0.148, executor driver, partition 1, PROCESS_LOCAL, 14185030 bytes) taskResourceAssignments Map()
21/12/06 17:37:51 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 19) in 252 ms on 192.168.0.148 (executor driver) (1/2)
21/12/06 17:37:51 INFO Executor: Running task 1.0 in stage 12.0 (TID 20)
21/12/06 17:37:51 INFO PythonRunner: Times: total = 138, boot = -1938, init = 1940, finish = 136
21/12/06 17:37:51 INFO Executor: Finished task 1.0 in stage 12.0 (TID 20). 561587 bytes result sent to driver
21/12/06 17:37:51 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 20) in 252 ms on 192.168.0.148 (executor driver) (2/2)
21/12/06 17:37:51 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/12/06 17:37:51 INFO DAGScheduler: ResultStage 12 (call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442) finished in 0.524 s
21/12/06 17:37:51 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
21/12/06 17:37:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
21/12/06 17:37:51 INFO DAGScheduler: Job 33 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.526211 s
21/12/06 17:37:51 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.0.148:33235 in memory (size: 5.8 KiB, free: 380.0 MiB)
21/12/06 17:37:52 INFO JobScheduler: Added jobs for time 1638792472000 ms
21/12/06 17:37:52 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:37:52 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:37:52 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:37:52 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:37:52 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:37:52 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:37:52 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:37:52 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:37:52 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:37:52 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:37:52 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:37:52 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792453000 ms.0 from job set of time 1638792453000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 19.871 s for time 1638792453000 ms (execution: 8.529 s)
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792454000 ms.0 from job set of time 1638792454000 ms
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 56 from persistence list
21/12/06 17:37:52 INFO BlockManager: Removing RDD 56
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[56] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792453000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792451000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792451000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 34 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000102 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792454000 ms.0 from job set of time 1638792454000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 18.882 s for time 1638792454000 ms (execution: 0.010 s)
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792455000 ms.0 from job set of time 1638792455000 ms
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 57 from persistence list
21/12/06 17:37:52 INFO BlockManager: Removing RDD 57
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[57] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792454000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792452000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792452000 ms
21/12/06 17:37:52 INFO BlockManagerInfo: Removed input-0-1638792452200 on 192.168.0.148:33235 in memory (size: 54.3 MiB, free: 434.4 MiB)
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 35 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000109 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792455000 ms.0 from job set of time 1638792455000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 17.893 s for time 1638792455000 ms (execution: 0.011 s)
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792456000 ms.0 from job set of time 1638792456000 ms
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 60 from persistence list
21/12/06 17:37:52 INFO BlockManager: Removing RDD 60
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[60] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792455000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792453000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792453000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 36 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000107 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792456000 ms.0 from job set of time 1638792456000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 16.905 s for time 1638792456000 ms (execution: 0.012 s)
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 61 from persistence list
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792457000 ms.0 from job set of time 1638792457000 ms
21/12/06 17:37:52 INFO BlockManager: Removing RDD 61
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[61] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792456000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792454000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792454000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 37 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000106 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792457000 ms.0 from job set of time 1638792457000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 15.916 s for time 1638792457000 ms (execution: 0.010 s)
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 62 from persistence list
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792458000 ms.0 from job set of time 1638792458000 ms
21/12/06 17:37:52 INFO BlockManager: Removing RDD 62
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[62] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792457000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792455000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792455000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 38 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000092 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792458000 ms.0 from job set of time 1638792458000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 14.926 s for time 1638792458000 ms (execution: 0.010 s)
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792459000 ms.0 from job set of time 1638792459000 ms
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 63 from persistence list
21/12/06 17:37:52 INFO BlockManager: Removing RDD 63
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[63] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792458000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792456000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792456000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 39 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000099 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792459000 ms.0 from job set of time 1638792459000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 13.937 s for time 1638792459000 ms (execution: 0.010 s)
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792460000 ms.0 from job set of time 1638792460000 ms
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 64 from persistence list
21/12/06 17:37:52 INFO BlockManager: Removing RDD 64
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[64] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792459000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792457000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792457000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 40 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000094 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792460000 ms.0 from job set of time 1638792460000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 12.948 s for time 1638792460000 ms (execution: 0.010 s)
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792461000 ms.0 from job set of time 1638792461000 ms
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 80 from persistence list
21/12/06 17:37:52 INFO BlockManager: Removing RDD 80
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[80] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792460000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792458000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792458000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 41 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000098 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792461000 ms.0 from job set of time 1638792461000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 11.959 s for time 1638792461000 ms (execution: 0.011 s)
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792462000 ms.0 from job set of time 1638792462000 ms
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 81 from persistence list
21/12/06 17:37:52 INFO BlockManager: Removing RDD 81
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[81] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792461000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792459000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792459000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 42 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000101 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792462000 ms.0 from job set of time 1638792462000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 10.972 s for time 1638792462000 ms (execution: 0.013 s)
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792463000 ms.0 from job set of time 1638792463000 ms
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 82 from persistence list
21/12/06 17:37:52 INFO BlockManager: Removing RDD 82
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[82] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792462000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792460000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792460000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 43 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000099 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792463000 ms.0 from job set of time 1638792463000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 9.981 s for time 1638792463000 ms (execution: 0.009 s)
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 83 from persistence list
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792464000 ms.0 from job set of time 1638792464000 ms
21/12/06 17:37:52 INFO BlockManager: Removing RDD 83
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[83] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792463000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792461000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792461000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:52 INFO DAGScheduler: Job 44 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000096 s
21/12/06 17:37:52 INFO JobScheduler: Finished job streaming job 1638792464000 ms.0 from job set of time 1638792464000 ms
21/12/06 17:37:52 INFO JobScheduler: Total delay: 8.991 s for time 1638792464000 ms (execution: 0.009 s)
21/12/06 17:37:52 INFO JobScheduler: Starting job streaming job 1638792465000 ms.0 from job set of time 1638792465000 ms
21/12/06 17:37:52 INFO BlockRDD: Removing RDD 86 from persistence list
21/12/06 17:37:52 INFO BlockManager: Removing RDD 86
21/12/06 17:37:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[86] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792464000 ms
21/12/06 17:37:52 INFO ReceivedBlockTracker: Deleting batches: 1638792462000 ms
21/12/06 17:37:52 INFO InputInfoTracker: remove old batch metadata: 1638792462000 ms
21/12/06 17:37:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:53 INFO DAGScheduler: Job 45 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000119 s
21/12/06 17:37:53 INFO JobScheduler: Added jobs for time 1638792473000 ms
21/12/06 17:37:53 INFO JobScheduler: Finished job streaming job 1638792465000 ms.0 from job set of time 1638792465000 ms
21/12/06 17:37:53 INFO JobScheduler: Total delay: 8.002 s for time 1638792465000 ms (execution: 0.011 s)
21/12/06 17:37:53 INFO JobScheduler: Starting job streaming job 1638792466000 ms.0 from job set of time 1638792466000 ms
21/12/06 17:37:53 INFO BlockRDD: Removing RDD 87 from persistence list
21/12/06 17:37:53 INFO BlockManager: Removing RDD 87
21/12/06 17:37:53 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[87] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792465000 ms
21/12/06 17:37:53 INFO ReceivedBlockTracker: Deleting batches: 1638792463000 ms
21/12/06 17:37:53 INFO InputInfoTracker: remove old batch metadata: 1638792463000 ms
21/12/06 17:37:53 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:53 INFO DAGScheduler: Job 46 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000114 s
21/12/06 17:37:53 INFO JobScheduler: Finished job streaming job 1638792466000 ms.0 from job set of time 1638792466000 ms
21/12/06 17:37:53 INFO JobScheduler: Total delay: 7.011 s for time 1638792466000 ms (execution: 0.009 s)
21/12/06 17:37:53 INFO JobScheduler: Starting job streaming job 1638792467000 ms.0 from job set of time 1638792467000 ms
21/12/06 17:37:53 INFO BlockRDD: Removing RDD 88 from persistence list
21/12/06 17:37:53 INFO BlockManager: Removing RDD 88
21/12/06 17:37:53 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[88] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792466000 ms
21/12/06 17:37:53 INFO ReceivedBlockTracker: Deleting batches: 1638792464000 ms
21/12/06 17:37:53 INFO InputInfoTracker: remove old batch metadata: 1638792464000 ms
21/12/06 17:37:53 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:53 INFO DAGScheduler: Job 47 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000098 s
21/12/06 17:37:53 INFO JobScheduler: Finished job streaming job 1638792467000 ms.0 from job set of time 1638792467000 ms
21/12/06 17:37:53 INFO JobScheduler: Total delay: 6.022 s for time 1638792467000 ms (execution: 0.011 s)
21/12/06 17:37:53 INFO JobScheduler: Starting job streaming job 1638792468000 ms.0 from job set of time 1638792468000 ms
21/12/06 17:37:53 INFO BlockRDD: Removing RDD 89 from persistence list
21/12/06 17:37:53 INFO BlockManager: Removing RDD 89
21/12/06 17:37:53 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[89] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792467000 ms
21/12/06 17:37:53 INFO ReceivedBlockTracker: Deleting batches: 1638792465000 ms
21/12/06 17:37:53 INFO InputInfoTracker: remove old batch metadata: 1638792465000 ms
21/12/06 17:37:53 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:53 INFO DAGScheduler: Job 48 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000092 s
21/12/06 17:37:53 INFO JobScheduler: Finished job streaming job 1638792468000 ms.0 from job set of time 1638792468000 ms
21/12/06 17:37:53 INFO JobScheduler: Total delay: 5.035 s for time 1638792468000 ms (execution: 0.012 s)
21/12/06 17:37:53 INFO JobScheduler: Starting job streaming job 1638792469000 ms.0 from job set of time 1638792469000 ms
21/12/06 17:37:53 INFO BlockRDD: Removing RDD 90 from persistence list
21/12/06 17:37:53 INFO BlockManager: Removing RDD 90
21/12/06 17:37:53 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[90] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792468000 ms
21/12/06 17:37:53 INFO ReceivedBlockTracker: Deleting batches: 1638792466000 ms
21/12/06 17:37:53 INFO InputInfoTracker: remove old batch metadata: 1638792466000 ms
21/12/06 17:37:53 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:53 INFO DAGScheduler: Job 49 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000113 s
21/12/06 17:37:53 INFO JobScheduler: Finished job streaming job 1638792469000 ms.0 from job set of time 1638792469000 ms
21/12/06 17:37:53 INFO JobScheduler: Total delay: 4.044 s for time 1638792469000 ms (execution: 0.009 s)
21/12/06 17:37:53 INFO JobScheduler: Starting job streaming job 1638792470000 ms.0 from job set of time 1638792470000 ms
21/12/06 17:37:53 INFO BlockRDD: Removing RDD 106 from persistence list
21/12/06 17:37:53 INFO BlockManager: Removing RDD 106
21/12/06 17:37:53 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[106] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792469000 ms
21/12/06 17:37:53 INFO ReceivedBlockTracker: Deleting batches: 1638792467000 ms
21/12/06 17:37:53 INFO InputInfoTracker: remove old batch metadata: 1638792467000 ms
21/12/06 17:37:53 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:53 INFO DAGScheduler: Job 50 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000101 s
21/12/06 17:37:53 INFO JobScheduler: Finished job streaming job 1638792470000 ms.0 from job set of time 1638792470000 ms
21/12/06 17:37:53 INFO JobScheduler: Total delay: 3.054 s for time 1638792470000 ms (execution: 0.010 s)
21/12/06 17:37:53 INFO JobScheduler: Starting job streaming job 1638792471000 ms.0 from job set of time 1638792471000 ms
21/12/06 17:37:53 INFO BlockRDD: Removing RDD 107 from persistence list
21/12/06 17:37:53 INFO BlockManager: Removing RDD 107
21/12/06 17:37:53 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[107] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792470000 ms
21/12/06 17:37:53 INFO ReceivedBlockTracker: Deleting batches: 1638792468000 ms
21/12/06 17:37:53 INFO InputInfoTracker: remove old batch metadata: 1638792468000 ms
21/12/06 17:37:53 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:53 INFO DAGScheduler: Job 51 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000123 s
21/12/06 17:37:53 INFO JobScheduler: Finished job streaming job 1638792471000 ms.0 from job set of time 1638792471000 ms
21/12/06 17:37:53 INFO JobScheduler: Total delay: 2.064 s for time 1638792471000 ms (execution: 0.010 s)
21/12/06 17:37:53 INFO JobScheduler: Starting job streaming job 1638792472000 ms.0 from job set of time 1638792472000 ms
21/12/06 17:37:53 INFO BlockRDD: Removing RDD 108 from persistence list
21/12/06 17:37:53 INFO BlockManager: Removing RDD 108
21/12/06 17:37:53 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[108] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792471000 ms
21/12/06 17:37:53 INFO ReceivedBlockTracker: Deleting batches: 1638792469000 ms
21/12/06 17:37:53 INFO InputInfoTracker: remove old batch metadata: 1638792469000 ms
21/12/06 17:37:53 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:53 INFO DAGScheduler: Job 52 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000085 s
21/12/06 17:37:53 INFO JobScheduler: Finished job streaming job 1638792472000 ms.0 from job set of time 1638792472000 ms
21/12/06 17:37:53 INFO JobScheduler: Total delay: 1.075 s for time 1638792472000 ms (execution: 0.011 s)
21/12/06 17:37:53 INFO JobScheduler: Starting job streaming job 1638792473000 ms.0 from job set of time 1638792473000 ms
21/12/06 17:37:53 INFO BlockRDD: Removing RDD 109 from persistence list
21/12/06 17:37:53 INFO BlockManager: Removing RDD 109
21/12/06 17:37:53 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[109] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792472000 ms
21/12/06 17:37:53 INFO ReceivedBlockTracker: Deleting batches: 1638792470000 ms
21/12/06 17:37:53 INFO InputInfoTracker: remove old batch metadata: 1638792470000 ms
21/12/06 17:37:53 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:53 INFO DAGScheduler: Job 53 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000081 s
21/12/06 17:37:53 INFO JobScheduler: Finished job streaming job 1638792473000 ms.0 from job set of time 1638792473000 ms
21/12/06 17:37:53 INFO JobScheduler: Total delay: 0.084 s for time 1638792473000 ms (execution: 0.009 s)
21/12/06 17:37:53 INFO BlockRDD: Removing RDD 112 from persistence list
21/12/06 17:37:53 INFO BlockManager: Removing RDD 112
21/12/06 17:37:53 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[112] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792473000 ms
21/12/06 17:37:53 INFO ReceivedBlockTracker: Deleting batches: 1638792471000 ms
21/12/06 17:37:53 INFO InputInfoTracker: remove old batch metadata: 1638792471000 ms
21/12/06 17:37:54 INFO JobScheduler: Added jobs for time 1638792474000 ms
21/12/06 17:37:54 INFO JobScheduler: Starting job streaming job 1638792474000 ms.0 from job set of time 1638792474000 ms
21/12/06 17:37:54 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:54 INFO DAGScheduler: Job 54 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000162 s
21/12/06 17:37:54 INFO JobScheduler: Finished job streaming job 1638792474000 ms.0 from job set of time 1638792474000 ms
21/12/06 17:37:54 INFO JobScheduler: Total delay: 0.025 s for time 1638792474000 ms (execution: 0.020 s)
21/12/06 17:37:54 INFO BlockRDD: Removing RDD 113 from persistence list
21/12/06 17:37:54 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[113] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792474000 ms
21/12/06 17:37:54 INFO ReceivedBlockTracker: Deleting batches: 1638792472000 ms
21/12/06 17:37:54 INFO InputInfoTracker: remove old batch metadata: 1638792472000 ms
21/12/06 17:37:54 INFO BlockManager: Removing RDD 113
21/12/06 17:37:54 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:37:54 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:37:54 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:37:54 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:37:54 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:37:54 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:37:54 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:37:54 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:37:54 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:37:54 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:37:54 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:37:54 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:37:55 INFO JobScheduler: Added jobs for time 1638792475000 ms
21/12/06 17:37:55 INFO JobScheduler: Starting job streaming job 1638792475000 ms.0 from job set of time 1638792475000 ms
21/12/06 17:37:55 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:55 INFO DAGScheduler: Job 55 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000154 s
21/12/06 17:37:55 INFO JobScheduler: Finished job streaming job 1638792475000 ms.0 from job set of time 1638792475000 ms
21/12/06 17:37:55 INFO JobScheduler: Total delay: 0.022 s for time 1638792475000 ms (execution: 0.019 s)
21/12/06 17:37:55 INFO BlockRDD: Removing RDD 114 from persistence list
21/12/06 17:37:55 INFO BlockManager: Removing RDD 114
21/12/06 17:37:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[114] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792475000 ms
21/12/06 17:37:55 INFO ReceivedBlockTracker: Deleting batches: 1638792473000 ms
21/12/06 17:37:55 INFO InputInfoTracker: remove old batch metadata: 1638792473000 ms
21/12/06 17:37:56 INFO JobScheduler: Added jobs for time 1638792476000 ms
21/12/06 17:37:56 INFO JobScheduler: Starting job streaming job 1638792476000 ms.0 from job set of time 1638792476000 ms
21/12/06 17:37:56 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:56 INFO DAGScheduler: Job 56 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000389 s
21/12/06 17:37:56 INFO JobScheduler: Finished job streaming job 1638792476000 ms.0 from job set of time 1638792476000 ms
21/12/06 17:37:56 INFO JobScheduler: Total delay: 0.016 s for time 1638792476000 ms (execution: 0.014 s)
21/12/06 17:37:56 INFO BlockRDD: Removing RDD 115 from persistence list
21/12/06 17:37:56 INFO BlockManager: Removing RDD 115
21/12/06 17:37:56 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[115] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792476000 ms
21/12/06 17:37:56 INFO ReceivedBlockTracker: Deleting batches: 1638792474000 ms
21/12/06 17:37:56 INFO InputInfoTracker: remove old batch metadata: 1638792474000 ms
21/12/06 17:37:56 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:37:56 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:37:56 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:37:56 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:37:56 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:37:56 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:37:56 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:37:56 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:37:56 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:37:56 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:37:56 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:37:56 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:37:57 INFO JobScheduler: Added jobs for time 1638792477000 ms
21/12/06 17:37:57 INFO JobScheduler: Starting job streaming job 1638792477000 ms.0 from job set of time 1638792477000 ms
21/12/06 17:37:57 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:57 INFO DAGScheduler: Job 57 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000371 s
21/12/06 17:37:57 INFO JobScheduler: Finished job streaming job 1638792477000 ms.0 from job set of time 1638792477000 ms
21/12/06 17:37:57 INFO JobScheduler: Total delay: 0.016 s for time 1638792477000 ms (execution: 0.014 s)
21/12/06 17:37:57 INFO BlockRDD: Removing RDD 116 from persistence list
21/12/06 17:37:57 INFO BlockManager: Removing RDD 116
21/12/06 17:37:57 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[116] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792477000 ms
21/12/06 17:37:57 INFO ReceivedBlockTracker: Deleting batches: 1638792475000 ms
21/12/06 17:37:57 INFO InputInfoTracker: remove old batch metadata: 1638792475000 ms
21/12/06 17:37:58 INFO JobScheduler: Added jobs for time 1638792478000 ms
21/12/06 17:37:58 INFO JobScheduler: Starting job streaming job 1638792478000 ms.0 from job set of time 1638792478000 ms
21/12/06 17:37:58 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:58 INFO DAGScheduler: Job 58 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000153 s
21/12/06 17:37:58 INFO JobScheduler: Finished job streaming job 1638792478000 ms.0 from job set of time 1638792478000 ms
21/12/06 17:37:58 INFO JobScheduler: Total delay: 0.020 s for time 1638792478000 ms (execution: 0.018 s)
21/12/06 17:37:58 INFO BlockRDD: Removing RDD 117 from persistence list
21/12/06 17:37:58 INFO BlockManager: Removing RDD 117
21/12/06 17:37:58 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[117] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792478000 ms
21/12/06 17:37:58 INFO ReceivedBlockTracker: Deleting batches: 1638792476000 ms
21/12/06 17:37:58 INFO InputInfoTracker: remove old batch metadata: 1638792476000 ms
21/12/06 17:37:58 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:37:58 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:37:58 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:37:58 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:37:58 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:37:58 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:37:58 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:37:58 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:37:58 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:37:58 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:37:58 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:37:58 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:37:59 INFO JobScheduler: Added jobs for time 1638792479000 ms
21/12/06 17:37:59 INFO JobScheduler: Starting job streaming job 1638792479000 ms.0 from job set of time 1638792479000 ms
21/12/06 17:37:59 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:37:59 INFO DAGScheduler: Job 59 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000140 s
21/12/06 17:37:59 INFO JobScheduler: Finished job streaming job 1638792479000 ms.0 from job set of time 1638792479000 ms
21/12/06 17:37:59 INFO JobScheduler: Total delay: 0.028 s for time 1638792479000 ms (execution: 0.023 s)
21/12/06 17:37:59 INFO BlockRDD: Removing RDD 118 from persistence list
21/12/06 17:37:59 INFO BlockManager: Removing RDD 118
21/12/06 17:37:59 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[118] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792479000 ms
21/12/06 17:37:59 INFO ReceivedBlockTracker: Deleting batches: 1638792477000 ms
21/12/06 17:37:59 INFO InputInfoTracker: remove old batch metadata: 1638792477000 ms
21/12/06 17:38:00 INFO JobScheduler: Added jobs for time 1638792480000 ms
21/12/06 17:38:00 INFO JobScheduler: Starting job streaming job 1638792480000 ms.0 from job set of time 1638792480000 ms
21/12/06 17:38:00 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:00 INFO DAGScheduler: Job 60 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000718 s
21/12/06 17:38:00 INFO JobScheduler: Finished job streaming job 1638792480000 ms.0 from job set of time 1638792480000 ms
21/12/06 17:38:00 INFO JobScheduler: Total delay: 0.015 s for time 1638792480000 ms (execution: 0.013 s)
21/12/06 17:38:00 INFO BlockRDD: Removing RDD 119 from persistence list
21/12/06 17:38:00 INFO BlockManager: Removing RDD 119
21/12/06 17:38:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[119] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792480000 ms
21/12/06 17:38:00 INFO ReceivedBlockTracker: Deleting batches: 1638792478000 ms
21/12/06 17:38:00 INFO InputInfoTracker: remove old batch metadata: 1638792478000 ms
21/12/06 17:38:00 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:00 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:00 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:00 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:00 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:00 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:00 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:00 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:00 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:00 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:00 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:00 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:01 INFO JobScheduler: Added jobs for time 1638792481000 ms
21/12/06 17:38:01 INFO JobScheduler: Starting job streaming job 1638792481000 ms.0 from job set of time 1638792481000 ms
21/12/06 17:38:01 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:01 INFO DAGScheduler: Job 61 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000459 s
21/12/06 17:38:01 INFO JobScheduler: Finished job streaming job 1638792481000 ms.0 from job set of time 1638792481000 ms
21/12/06 17:38:01 INFO JobScheduler: Total delay: 0.021 s for time 1638792481000 ms (execution: 0.018 s)
21/12/06 17:38:01 INFO BlockRDD: Removing RDD 120 from persistence list
21/12/06 17:38:01 INFO BlockManager: Removing RDD 120
21/12/06 17:38:01 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[120] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792481000 ms
21/12/06 17:38:01 INFO ReceivedBlockTracker: Deleting batches: 1638792479000 ms
21/12/06 17:38:01 INFO InputInfoTracker: remove old batch metadata: 1638792479000 ms
21/12/06 17:38:02 INFO JobScheduler: Added jobs for time 1638792482000 ms
21/12/06 17:38:02 INFO JobScheduler: Starting job streaming job 1638792482000 ms.0 from job set of time 1638792482000 ms
21/12/06 17:38:02 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:02 INFO DAGScheduler: Job 62 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000151 s
21/12/06 17:38:02 INFO JobScheduler: Finished job streaming job 1638792482000 ms.0 from job set of time 1638792482000 ms
21/12/06 17:38:02 INFO JobScheduler: Total delay: 0.028 s for time 1638792482000 ms (execution: 0.025 s)
21/12/06 17:38:02 INFO BlockRDD: Removing RDD 121 from persistence list
21/12/06 17:38:02 INFO BlockManager: Removing RDD 121
21/12/06 17:38:02 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[121] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792482000 ms
21/12/06 17:38:02 INFO ReceivedBlockTracker: Deleting batches: 1638792480000 ms
21/12/06 17:38:02 INFO InputInfoTracker: remove old batch metadata: 1638792480000 ms
21/12/06 17:38:02 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:02 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:02 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:02 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:02 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:02 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:02 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:02 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:02 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:02 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:02 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:02 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:03 INFO JobScheduler: Added jobs for time 1638792483000 ms
21/12/06 17:38:03 INFO JobScheduler: Starting job streaming job 1638792483000 ms.0 from job set of time 1638792483000 ms
21/12/06 17:38:03 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:03 INFO DAGScheduler: Job 63 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000167 s
21/12/06 17:38:03 INFO JobScheduler: Finished job streaming job 1638792483000 ms.0 from job set of time 1638792483000 ms
21/12/06 17:38:03 INFO JobScheduler: Total delay: 0.025 s for time 1638792483000 ms (execution: 0.022 s)
21/12/06 17:38:03 INFO BlockRDD: Removing RDD 122 from persistence list
21/12/06 17:38:03 INFO BlockManager: Removing RDD 122
21/12/06 17:38:03 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[122] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792483000 ms
21/12/06 17:38:03 INFO ReceivedBlockTracker: Deleting batches: 1638792481000 ms
21/12/06 17:38:03 INFO InputInfoTracker: remove old batch metadata: 1638792481000 ms
21/12/06 17:38:04 INFO JobScheduler: Added jobs for time 1638792484000 ms
21/12/06 17:38:04 INFO JobScheduler: Starting job streaming job 1638792484000 ms.0 from job set of time 1638792484000 ms
21/12/06 17:38:04 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:04 INFO DAGScheduler: Job 64 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000357 s
21/12/06 17:38:04 INFO JobScheduler: Finished job streaming job 1638792484000 ms.0 from job set of time 1638792484000 ms
21/12/06 17:38:04 INFO JobScheduler: Total delay: 0.023 s for time 1638792484000 ms (execution: 0.022 s)
21/12/06 17:38:04 INFO BlockRDD: Removing RDD 123 from persistence list
21/12/06 17:38:04 INFO BlockManager: Removing RDD 123
21/12/06 17:38:04 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[123] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792484000 ms
21/12/06 17:38:04 INFO ReceivedBlockTracker: Deleting batches: 1638792482000 ms
21/12/06 17:38:04 INFO InputInfoTracker: remove old batch metadata: 1638792482000 ms
21/12/06 17:38:04 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:04 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:04 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:04 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:04 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:04 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:04 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:04 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:04 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:04 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:04 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:04 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:05 INFO JobScheduler: Added jobs for time 1638792485000 ms
21/12/06 17:38:05 INFO JobScheduler: Starting job streaming job 1638792485000 ms.0 from job set of time 1638792485000 ms
21/12/06 17:38:05 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:05 INFO DAGScheduler: Job 65 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000669 s
21/12/06 17:38:05 INFO JobScheduler: Finished job streaming job 1638792485000 ms.0 from job set of time 1638792485000 ms
21/12/06 17:38:05 INFO JobScheduler: Total delay: 0.042 s for time 1638792485000 ms (execution: 0.036 s)
21/12/06 17:38:05 INFO BlockRDD: Removing RDD 124 from persistence list
21/12/06 17:38:05 INFO BlockManager: Removing RDD 124
21/12/06 17:38:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[124] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792485000 ms
21/12/06 17:38:05 INFO ReceivedBlockTracker: Deleting batches: 1638792483000 ms
21/12/06 17:38:05 INFO InputInfoTracker: remove old batch metadata: 1638792483000 ms
21/12/06 17:38:06 INFO JobScheduler: Added jobs for time 1638792486000 ms
21/12/06 17:38:06 INFO JobScheduler: Starting job streaming job 1638792486000 ms.0 from job set of time 1638792486000 ms
21/12/06 17:38:06 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:06 INFO DAGScheduler: Job 66 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000156 s
21/12/06 17:38:06 INFO JobScheduler: Finished job streaming job 1638792486000 ms.0 from job set of time 1638792486000 ms
21/12/06 17:38:06 INFO JobScheduler: Total delay: 0.013 s for time 1638792486000 ms (execution: 0.011 s)
21/12/06 17:38:06 INFO BlockRDD: Removing RDD 125 from persistence list
21/12/06 17:38:06 INFO BlockManager: Removing RDD 125
21/12/06 17:38:06 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[125] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792486000 ms
21/12/06 17:38:06 INFO ReceivedBlockTracker: Deleting batches: 1638792484000 ms
21/12/06 17:38:06 INFO InputInfoTracker: remove old batch metadata: 1638792484000 ms
21/12/06 17:38:06 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:06 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:06 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:06 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:06 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:06 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:06 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:06 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:06 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:06 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:06 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:06 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:07 INFO JobScheduler: Added jobs for time 1638792487000 ms
21/12/06 17:38:07 INFO JobScheduler: Starting job streaming job 1638792487000 ms.0 from job set of time 1638792487000 ms
21/12/06 17:38:07 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:07 INFO DAGScheduler: Job 67 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000096 s
21/12/06 17:38:07 INFO JobScheduler: Finished job streaming job 1638792487000 ms.0 from job set of time 1638792487000 ms
21/12/06 17:38:07 INFO JobScheduler: Total delay: 0.013 s for time 1638792487000 ms (execution: 0.010 s)
21/12/06 17:38:07 INFO BlockRDD: Removing RDD 126 from persistence list
21/12/06 17:38:07 INFO BlockManager: Removing RDD 126
21/12/06 17:38:07 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[126] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792487000 ms
21/12/06 17:38:07 INFO ReceivedBlockTracker: Deleting batches: 1638792485000 ms
21/12/06 17:38:07 INFO InputInfoTracker: remove old batch metadata: 1638792485000 ms
21/12/06 17:38:08 INFO JobScheduler: Starting job streaming job 1638792488000 ms.0 from job set of time 1638792488000 ms
21/12/06 17:38:08 INFO JobScheduler: Added jobs for time 1638792488000 ms
21/12/06 17:38:08 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:08 INFO DAGScheduler: Job 68 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000382 s
21/12/06 17:38:08 INFO JobScheduler: Finished job streaming job 1638792488000 ms.0 from job set of time 1638792488000 ms
21/12/06 17:38:08 INFO JobScheduler: Total delay: 0.014 s for time 1638792488000 ms (execution: 0.012 s)
21/12/06 17:38:08 INFO BlockRDD: Removing RDD 127 from persistence list
21/12/06 17:38:08 INFO BlockManager: Removing RDD 127
21/12/06 17:38:08 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[127] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792488000 ms
21/12/06 17:38:08 INFO ReceivedBlockTracker: Deleting batches: 1638792486000 ms
21/12/06 17:38:08 INFO InputInfoTracker: remove old batch metadata: 1638792486000 ms
21/12/06 17:38:08 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:08 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:08 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:08 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:08 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:08 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:08 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:08 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:08 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:08 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:08 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:08 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:09 INFO JobScheduler: Added jobs for time 1638792489000 ms
21/12/06 17:38:09 INFO JobScheduler: Starting job streaming job 1638792489000 ms.0 from job set of time 1638792489000 ms
21/12/06 17:38:09 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:09 INFO DAGScheduler: Job 69 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000175 s
21/12/06 17:38:09 INFO JobScheduler: Finished job streaming job 1638792489000 ms.0 from job set of time 1638792489000 ms
21/12/06 17:38:09 INFO JobScheduler: Total delay: 0.034 s for time 1638792489000 ms (execution: 0.029 s)
21/12/06 17:38:09 INFO BlockRDD: Removing RDD 128 from persistence list
21/12/06 17:38:09 INFO BlockManager: Removing RDD 128
21/12/06 17:38:09 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[128] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792489000 ms
21/12/06 17:38:09 INFO ReceivedBlockTracker: Deleting batches: 1638792487000 ms
21/12/06 17:38:09 INFO InputInfoTracker: remove old batch metadata: 1638792487000 ms
21/12/06 17:38:10 INFO JobScheduler: Added jobs for time 1638792490000 ms
21/12/06 17:38:10 INFO JobScheduler: Starting job streaming job 1638792490000 ms.0 from job set of time 1638792490000 ms
21/12/06 17:38:10 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:10 INFO DAGScheduler: Job 70 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000096 s
21/12/06 17:38:10 INFO JobScheduler: Finished job streaming job 1638792490000 ms.0 from job set of time 1638792490000 ms
21/12/06 17:38:10 INFO JobScheduler: Total delay: 0.016 s for time 1638792490000 ms (execution: 0.015 s)
21/12/06 17:38:10 INFO BlockRDD: Removing RDD 129 from persistence list
21/12/06 17:38:10 INFO BlockManager: Removing RDD 129
21/12/06 17:38:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[129] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792490000 ms
21/12/06 17:38:10 INFO ReceivedBlockTracker: Deleting batches: 1638792488000 ms
21/12/06 17:38:10 INFO InputInfoTracker: remove old batch metadata: 1638792488000 ms
21/12/06 17:38:10 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:10 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:10 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:10 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:10 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:10 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:10 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:10 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:10 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:10 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:10 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:10 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:11 INFO JobScheduler: Added jobs for time 1638792491000 ms
21/12/06 17:38:11 INFO JobScheduler: Starting job streaming job 1638792491000 ms.0 from job set of time 1638792491000 ms
21/12/06 17:38:11 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:11 INFO DAGScheduler: Job 71 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000646 s
21/12/06 17:38:11 INFO JobScheduler: Finished job streaming job 1638792491000 ms.0 from job set of time 1638792491000 ms
21/12/06 17:38:11 INFO JobScheduler: Total delay: 0.025 s for time 1638792491000 ms (execution: 0.022 s)
21/12/06 17:38:11 INFO BlockRDD: Removing RDD 130 from persistence list
21/12/06 17:38:11 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[130] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792491000 ms
21/12/06 17:38:11 INFO ReceivedBlockTracker: Deleting batches: 1638792489000 ms
21/12/06 17:38:11 INFO InputInfoTracker: remove old batch metadata: 1638792489000 ms
21/12/06 17:38:11 INFO BlockManager: Removing RDD 130
21/12/06 17:38:12 INFO JobScheduler: Added jobs for time 1638792492000 ms
21/12/06 17:38:12 INFO JobScheduler: Starting job streaming job 1638792492000 ms.0 from job set of time 1638792492000 ms
21/12/06 17:38:12 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:12 INFO DAGScheduler: Job 72 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000124 s
21/12/06 17:38:12 INFO JobScheduler: Finished job streaming job 1638792492000 ms.0 from job set of time 1638792492000 ms
21/12/06 17:38:12 INFO JobScheduler: Total delay: 0.035 s for time 1638792492000 ms (execution: 0.029 s)
21/12/06 17:38:12 INFO BlockRDD: Removing RDD 131 from persistence list
21/12/06 17:38:12 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[131] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792492000 ms
21/12/06 17:38:12 INFO ReceivedBlockTracker: Deleting batches: 1638792490000 ms
21/12/06 17:38:12 INFO InputInfoTracker: remove old batch metadata: 1638792490000 ms
21/12/06 17:38:12 INFO BlockManager: Removing RDD 131
21/12/06 17:38:12 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:12 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:12 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:12 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:12 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:12 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:12 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:12 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:12 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:12 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:12 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:13 INFO JobScheduler: Added jobs for time 1638792493000 ms
21/12/06 17:38:13 INFO JobScheduler: Starting job streaming job 1638792493000 ms.0 from job set of time 1638792493000 ms
21/12/06 17:38:13 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:13 INFO DAGScheduler: Job 73 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000100 s
21/12/06 17:38:13 INFO JobScheduler: Finished job streaming job 1638792493000 ms.0 from job set of time 1638792493000 ms
21/12/06 17:38:13 INFO JobScheduler: Total delay: 0.015 s for time 1638792493000 ms (execution: 0.011 s)
21/12/06 17:38:13 INFO BlockRDD: Removing RDD 132 from persistence list
21/12/06 17:38:13 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[132] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792493000 ms
21/12/06 17:38:13 INFO ReceivedBlockTracker: Deleting batches: 1638792491000 ms
21/12/06 17:38:13 INFO InputInfoTracker: remove old batch metadata: 1638792491000 ms
21/12/06 17:38:13 INFO BlockManager: Removing RDD 132
21/12/06 17:38:14 INFO JobScheduler: Added jobs for time 1638792494000 ms
21/12/06 17:38:14 INFO JobScheduler: Starting job streaming job 1638792494000 ms.0 from job set of time 1638792494000 ms
21/12/06 17:38:14 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:14 INFO DAGScheduler: Job 74 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000132 s
21/12/06 17:38:14 INFO JobScheduler: Finished job streaming job 1638792494000 ms.0 from job set of time 1638792494000 ms
21/12/06 17:38:14 INFO JobScheduler: Total delay: 0.019 s for time 1638792494000 ms (execution: 0.017 s)
21/12/06 17:38:14 INFO BlockRDD: Removing RDD 133 from persistence list
21/12/06 17:38:14 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[133] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792494000 ms
21/12/06 17:38:14 INFO ReceivedBlockTracker: Deleting batches: 1638792492000 ms
21/12/06 17:38:14 INFO InputInfoTracker: remove old batch metadata: 1638792492000 ms
21/12/06 17:38:14 INFO BlockManager: Removing RDD 133
21/12/06 17:38:14 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:14 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:14 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:14 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:14 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:14 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:14 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:14 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:14 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:14 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:14 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:15 INFO JobScheduler: Added jobs for time 1638792495000 ms
21/12/06 17:38:15 INFO JobScheduler: Starting job streaming job 1638792495000 ms.0 from job set of time 1638792495000 ms
21/12/06 17:38:15 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:15 INFO DAGScheduler: Job 75 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000172 s
21/12/06 17:38:15 INFO JobScheduler: Finished job streaming job 1638792495000 ms.0 from job set of time 1638792495000 ms
21/12/06 17:38:15 INFO JobScheduler: Total delay: 0.028 s for time 1638792495000 ms (execution: 0.024 s)
21/12/06 17:38:15 INFO BlockRDD: Removing RDD 134 from persistence list
21/12/06 17:38:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[134] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792495000 ms
21/12/06 17:38:15 INFO BlockManager: Removing RDD 134
21/12/06 17:38:15 INFO ReceivedBlockTracker: Deleting batches: 1638792493000 ms
21/12/06 17:38:15 INFO InputInfoTracker: remove old batch metadata: 1638792493000 ms
21/12/06 17:38:16 INFO JobScheduler: Added jobs for time 1638792496000 ms
21/12/06 17:38:16 INFO JobScheduler: Starting job streaming job 1638792496000 ms.0 from job set of time 1638792496000 ms
21/12/06 17:38:16 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:16 INFO DAGScheduler: Job 76 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000099 s
21/12/06 17:38:16 INFO JobScheduler: Finished job streaming job 1638792496000 ms.0 from job set of time 1638792496000 ms
21/12/06 17:38:16 INFO JobScheduler: Total delay: 0.014 s for time 1638792496000 ms (execution: 0.013 s)
21/12/06 17:38:16 INFO BlockRDD: Removing RDD 135 from persistence list
21/12/06 17:38:16 INFO BlockManager: Removing RDD 135
21/12/06 17:38:16 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[135] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792496000 ms
21/12/06 17:38:16 INFO ReceivedBlockTracker: Deleting batches: 1638792494000 ms
21/12/06 17:38:16 INFO InputInfoTracker: remove old batch metadata: 1638792494000 ms
21/12/06 17:38:16 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:16 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:16 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:16 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:16 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:16 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:16 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:16 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:16 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:16 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:16 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:17 INFO JobScheduler: Added jobs for time 1638792497000 ms
21/12/06 17:38:17 INFO JobScheduler: Starting job streaming job 1638792497000 ms.0 from job set of time 1638792497000 ms
21/12/06 17:38:17 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:17 INFO DAGScheduler: Job 77 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000250 s
21/12/06 17:38:17 INFO JobScheduler: Finished job streaming job 1638792497000 ms.0 from job set of time 1638792497000 ms
21/12/06 17:38:17 INFO JobScheduler: Total delay: 0.015 s for time 1638792497000 ms (execution: 0.013 s)
21/12/06 17:38:17 INFO BlockRDD: Removing RDD 136 from persistence list
21/12/06 17:38:17 INFO BlockManager: Removing RDD 136
21/12/06 17:38:17 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[136] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792497000 ms
21/12/06 17:38:17 INFO ReceivedBlockTracker: Deleting batches: 1638792495000 ms
21/12/06 17:38:17 INFO InputInfoTracker: remove old batch metadata: 1638792495000 ms
21/12/06 17:38:18 INFO JobScheduler: Added jobs for time 1638792498000 ms
21/12/06 17:38:18 INFO JobScheduler: Starting job streaming job 1638792498000 ms.0 from job set of time 1638792498000 ms
21/12/06 17:38:18 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:18 INFO DAGScheduler: Job 78 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000485 s
21/12/06 17:38:18 INFO JobScheduler: Finished job streaming job 1638792498000 ms.0 from job set of time 1638792498000 ms
21/12/06 17:38:18 INFO JobScheduler: Total delay: 0.025 s for time 1638792498000 ms (execution: 0.021 s)
21/12/06 17:38:18 INFO BlockRDD: Removing RDD 137 from persistence list
21/12/06 17:38:18 INFO BlockManager: Removing RDD 137
21/12/06 17:38:18 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[137] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792498000 ms
21/12/06 17:38:18 INFO ReceivedBlockTracker: Deleting batches: 1638792496000 ms
21/12/06 17:38:18 INFO InputInfoTracker: remove old batch metadata: 1638792496000 ms
21/12/06 17:38:18 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:18 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:18 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:18 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:18 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:18 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:18 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:18 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:18 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:18 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:18 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:19 INFO JobScheduler: Added jobs for time 1638792499000 ms
21/12/06 17:38:19 INFO JobScheduler: Starting job streaming job 1638792499000 ms.0 from job set of time 1638792499000 ms
21/12/06 17:38:19 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:19 INFO DAGScheduler: Job 79 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000150 s
21/12/06 17:38:19 INFO JobScheduler: Finished job streaming job 1638792499000 ms.0 from job set of time 1638792499000 ms
21/12/06 17:38:19 INFO JobScheduler: Total delay: 0.021 s for time 1638792499000 ms (execution: 0.015 s)
21/12/06 17:38:19 INFO BlockRDD: Removing RDD 138 from persistence list
21/12/06 17:38:19 INFO BlockManager: Removing RDD 138
21/12/06 17:38:19 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[138] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792499000 ms
21/12/06 17:38:19 INFO ReceivedBlockTracker: Deleting batches: 1638792497000 ms
21/12/06 17:38:19 INFO InputInfoTracker: remove old batch metadata: 1638792497000 ms
21/12/06 17:38:20 INFO JobScheduler: Added jobs for time 1638792500000 ms
21/12/06 17:38:20 INFO JobScheduler: Starting job streaming job 1638792500000 ms.0 from job set of time 1638792500000 ms
21/12/06 17:38:20 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:20 INFO DAGScheduler: Job 80 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000091 s
21/12/06 17:38:20 INFO JobScheduler: Finished job streaming job 1638792500000 ms.0 from job set of time 1638792500000 ms
21/12/06 17:38:20 INFO JobScheduler: Total delay: 0.018 s for time 1638792500000 ms (execution: 0.016 s)
21/12/06 17:38:20 INFO BlockRDD: Removing RDD 139 from persistence list
21/12/06 17:38:20 INFO BlockManager: Removing RDD 139
21/12/06 17:38:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[139] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792500000 ms
21/12/06 17:38:20 INFO ReceivedBlockTracker: Deleting batches: 1638792498000 ms
21/12/06 17:38:20 INFO InputInfoTracker: remove old batch metadata: 1638792498000 ms
21/12/06 17:38:20 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:20 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:20 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:20 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:20 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:20 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:20 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:20 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:20 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:20 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:20 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:21 INFO JobScheduler: Added jobs for time 1638792501000 ms
21/12/06 17:38:21 INFO JobScheduler: Starting job streaming job 1638792501000 ms.0 from job set of time 1638792501000 ms
21/12/06 17:38:21 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:21 INFO DAGScheduler: Job 81 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000100 s
21/12/06 17:38:21 INFO JobScheduler: Finished job streaming job 1638792501000 ms.0 from job set of time 1638792501000 ms
21/12/06 17:38:21 INFO JobScheduler: Total delay: 0.018 s for time 1638792501000 ms (execution: 0.014 s)
21/12/06 17:38:21 INFO BlockRDD: Removing RDD 140 from persistence list
21/12/06 17:38:21 INFO BlockManager: Removing RDD 140
21/12/06 17:38:21 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[140] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792501000 ms
21/12/06 17:38:21 INFO ReceivedBlockTracker: Deleting batches: 1638792499000 ms
21/12/06 17:38:21 INFO InputInfoTracker: remove old batch metadata: 1638792499000 ms
21/12/06 17:38:22 INFO JobScheduler: Added jobs for time 1638792502000 ms
21/12/06 17:38:22 INFO JobScheduler: Starting job streaming job 1638792502000 ms.0 from job set of time 1638792502000 ms
21/12/06 17:38:22 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:22 INFO DAGScheduler: Job 82 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000093 s
21/12/06 17:38:22 INFO JobScheduler: Finished job streaming job 1638792502000 ms.0 from job set of time 1638792502000 ms
21/12/06 17:38:22 INFO JobScheduler: Total delay: 0.013 s for time 1638792502000 ms (execution: 0.011 s)
21/12/06 17:38:22 INFO BlockRDD: Removing RDD 141 from persistence list
21/12/06 17:38:22 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[141] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792502000 ms
21/12/06 17:38:22 INFO ReceivedBlockTracker: Deleting batches: 1638792500000 ms
21/12/06 17:38:22 INFO InputInfoTracker: remove old batch metadata: 1638792500000 ms
21/12/06 17:38:22 INFO BlockManager: Removing RDD 141
21/12/06 17:38:22 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:22 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:22 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:22 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:22 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:22 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:22 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:22 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:22 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:22 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:22 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:23 INFO JobScheduler: Added jobs for time 1638792503000 ms
21/12/06 17:38:23 INFO JobScheduler: Starting job streaming job 1638792503000 ms.0 from job set of time 1638792503000 ms
21/12/06 17:38:23 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:23 INFO DAGScheduler: Job 83 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000448 s
21/12/06 17:38:23 INFO JobScheduler: Finished job streaming job 1638792503000 ms.0 from job set of time 1638792503000 ms
21/12/06 17:38:23 INFO JobScheduler: Total delay: 0.023 s for time 1638792503000 ms (execution: 0.020 s)
21/12/06 17:38:23 INFO BlockRDD: Removing RDD 142 from persistence list
21/12/06 17:38:23 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[142] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792503000 ms
21/12/06 17:38:23 INFO ReceivedBlockTracker: Deleting batches: 1638792501000 ms
21/12/06 17:38:23 INFO BlockManager: Removing RDD 142
21/12/06 17:38:23 INFO InputInfoTracker: remove old batch metadata: 1638792501000 ms
21/12/06 17:38:24 INFO JobScheduler: Added jobs for time 1638792504000 ms
21/12/06 17:38:24 INFO JobScheduler: Starting job streaming job 1638792504000 ms.0 from job set of time 1638792504000 ms
21/12/06 17:38:24 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:24 INFO DAGScheduler: Job 84 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000312 s
21/12/06 17:38:24 INFO JobScheduler: Finished job streaming job 1638792504000 ms.0 from job set of time 1638792504000 ms
21/12/06 17:38:24 INFO JobScheduler: Total delay: 0.016 s for time 1638792504000 ms (execution: 0.013 s)
21/12/06 17:38:24 INFO BlockRDD: Removing RDD 143 from persistence list
21/12/06 17:38:24 INFO BlockManager: Removing RDD 143
21/12/06 17:38:24 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[143] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792504000 ms
21/12/06 17:38:24 INFO ReceivedBlockTracker: Deleting batches: 1638792502000 ms
21/12/06 17:38:24 INFO InputInfoTracker: remove old batch metadata: 1638792502000 ms
21/12/06 17:38:24 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:24 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:24 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:24 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:24 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:24 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:24 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:24 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:24 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:24 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:24 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:25 INFO JobScheduler: Added jobs for time 1638792505000 ms
21/12/06 17:38:25 INFO JobScheduler: Starting job streaming job 1638792505000 ms.0 from job set of time 1638792505000 ms
21/12/06 17:38:25 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:25 INFO DAGScheduler: Job 85 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000100 s
21/12/06 17:38:25 INFO JobScheduler: Finished job streaming job 1638792505000 ms.0 from job set of time 1638792505000 ms
21/12/06 17:38:25 INFO JobScheduler: Total delay: 0.015 s for time 1638792505000 ms (execution: 0.012 s)
21/12/06 17:38:25 INFO BlockRDD: Removing RDD 144 from persistence list
21/12/06 17:38:25 INFO BlockManager: Removing RDD 144
21/12/06 17:38:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[144] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792505000 ms
21/12/06 17:38:25 INFO ReceivedBlockTracker: Deleting batches: 1638792503000 ms
21/12/06 17:38:25 INFO InputInfoTracker: remove old batch metadata: 1638792503000 ms
21/12/06 17:38:26 INFO JobScheduler: Added jobs for time 1638792506000 ms
21/12/06 17:38:26 INFO JobScheduler: Starting job streaming job 1638792506000 ms.0 from job set of time 1638792506000 ms
21/12/06 17:38:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:26 INFO DAGScheduler: Job 86 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000140 s
21/12/06 17:38:26 INFO JobScheduler: Finished job streaming job 1638792506000 ms.0 from job set of time 1638792506000 ms
21/12/06 17:38:26 INFO JobScheduler: Total delay: 0.029 s for time 1638792506000 ms (execution: 0.025 s)
21/12/06 17:38:26 INFO BlockRDD: Removing RDD 145 from persistence list
21/12/06 17:38:26 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[145] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792506000 ms
21/12/06 17:38:26 INFO ReceivedBlockTracker: Deleting batches: 1638792504000 ms
21/12/06 17:38:26 INFO InputInfoTracker: remove old batch metadata: 1638792504000 ms
21/12/06 17:38:26 INFO BlockManager: Removing RDD 145
21/12/06 17:38:26 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:26 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:26 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:26 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:26 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:26 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:26 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:26 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:26 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:26 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:26 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:27 INFO JobScheduler: Added jobs for time 1638792507000 ms
21/12/06 17:38:27 INFO JobScheduler: Starting job streaming job 1638792507000 ms.0 from job set of time 1638792507000 ms
21/12/06 17:38:27 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:27 INFO DAGScheduler: Job 87 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000279 s
21/12/06 17:38:27 INFO JobScheduler: Finished job streaming job 1638792507000 ms.0 from job set of time 1638792507000 ms
21/12/06 17:38:27 INFO JobScheduler: Total delay: 0.034 s for time 1638792507000 ms (execution: 0.030 s)
21/12/06 17:38:27 INFO BlockRDD: Removing RDD 146 from persistence list
21/12/06 17:38:27 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[146] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792507000 ms
21/12/06 17:38:27 INFO ReceivedBlockTracker: Deleting batches: 1638792505000 ms
21/12/06 17:38:27 INFO InputInfoTracker: remove old batch metadata: 1638792505000 ms
21/12/06 17:38:27 INFO BlockManager: Removing RDD 146
21/12/06 17:38:28 INFO JobScheduler: Added jobs for time 1638792508000 ms
21/12/06 17:38:28 INFO JobScheduler: Starting job streaming job 1638792508000 ms.0 from job set of time 1638792508000 ms
21/12/06 17:38:28 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:28 INFO DAGScheduler: Job 88 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000205 s
21/12/06 17:38:28 INFO JobScheduler: Finished job streaming job 1638792508000 ms.0 from job set of time 1638792508000 ms
21/12/06 17:38:28 INFO JobScheduler: Total delay: 0.016 s for time 1638792508000 ms (execution: 0.014 s)
21/12/06 17:38:28 INFO BlockRDD: Removing RDD 147 from persistence list
21/12/06 17:38:28 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[147] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792508000 ms
21/12/06 17:38:28 INFO ReceivedBlockTracker: Deleting batches: 1638792506000 ms
21/12/06 17:38:28 INFO InputInfoTracker: remove old batch metadata: 1638792506000 ms
21/12/06 17:38:28 INFO BlockManager: Removing RDD 147
21/12/06 17:38:28 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:28 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:28 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:28 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:28 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:28 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:28 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:28 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:28 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:28 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:28 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:29 INFO JobScheduler: Added jobs for time 1638792509000 ms
21/12/06 17:38:29 INFO JobScheduler: Starting job streaming job 1638792509000 ms.0 from job set of time 1638792509000 ms
21/12/06 17:38:29 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:29 INFO DAGScheduler: Job 89 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000400 s
21/12/06 17:38:29 INFO JobScheduler: Finished job streaming job 1638792509000 ms.0 from job set of time 1638792509000 ms
21/12/06 17:38:29 INFO JobScheduler: Total delay: 0.031 s for time 1638792509000 ms (execution: 0.027 s)
21/12/06 17:38:29 INFO BlockRDD: Removing RDD 148 from persistence list
21/12/06 17:38:29 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[148] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792509000 ms
21/12/06 17:38:29 INFO ReceivedBlockTracker: Deleting batches: 1638792507000 ms
21/12/06 17:38:29 INFO InputInfoTracker: remove old batch metadata: 1638792507000 ms
21/12/06 17:38:29 INFO BlockManager: Removing RDD 148
21/12/06 17:38:30 INFO JobScheduler: Added jobs for time 1638792510000 ms
21/12/06 17:38:30 INFO JobScheduler: Starting job streaming job 1638792510000 ms.0 from job set of time 1638792510000 ms
21/12/06 17:38:30 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:30 INFO DAGScheduler: Job 90 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000557 s
21/12/06 17:38:30 INFO JobScheduler: Finished job streaming job 1638792510000 ms.0 from job set of time 1638792510000 ms
21/12/06 17:38:30 INFO JobScheduler: Total delay: 0.030 s for time 1638792510000 ms (execution: 0.024 s)
21/12/06 17:38:30 INFO BlockRDD: Removing RDD 149 from persistence list
21/12/06 17:38:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[149] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792510000 ms
21/12/06 17:38:30 INFO ReceivedBlockTracker: Deleting batches: 1638792508000 ms
21/12/06 17:38:30 INFO InputInfoTracker: remove old batch metadata: 1638792508000 ms
21/12/06 17:38:30 INFO BlockManager: Removing RDD 149
21/12/06 17:38:30 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:30 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:30 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:30 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:30 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:30 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:30 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:30 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:30 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:30 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:30 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:31 INFO JobScheduler: Added jobs for time 1638792511000 ms
21/12/06 17:38:31 INFO JobScheduler: Starting job streaming job 1638792511000 ms.0 from job set of time 1638792511000 ms
21/12/06 17:38:31 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:31 INFO DAGScheduler: Job 91 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000094 s
21/12/06 17:38:31 INFO JobScheduler: Finished job streaming job 1638792511000 ms.0 from job set of time 1638792511000 ms
21/12/06 17:38:31 INFO JobScheduler: Total delay: 0.020 s for time 1638792511000 ms (execution: 0.017 s)
21/12/06 17:38:31 INFO BlockRDD: Removing RDD 150 from persistence list
21/12/06 17:38:31 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[150] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792511000 ms
21/12/06 17:38:31 INFO ReceivedBlockTracker: Deleting batches: 1638792509000 ms
21/12/06 17:38:31 INFO InputInfoTracker: remove old batch metadata: 1638792509000 ms
21/12/06 17:38:31 INFO BlockManager: Removing RDD 150
21/12/06 17:38:32 INFO JobScheduler: Added jobs for time 1638792512000 ms
21/12/06 17:38:32 INFO JobScheduler: Starting job streaming job 1638792512000 ms.0 from job set of time 1638792512000 ms
21/12/06 17:38:32 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:32 INFO DAGScheduler: Job 92 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000105 s
21/12/06 17:38:32 INFO JobScheduler: Finished job streaming job 1638792512000 ms.0 from job set of time 1638792512000 ms
21/12/06 17:38:32 INFO JobScheduler: Total delay: 0.011 s for time 1638792512000 ms (execution: 0.010 s)
21/12/06 17:38:32 INFO BlockRDD: Removing RDD 151 from persistence list
21/12/06 17:38:32 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[151] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792512000 ms
21/12/06 17:38:32 INFO ReceivedBlockTracker: Deleting batches: 1638792510000 ms
21/12/06 17:38:32 INFO BlockManager: Removing RDD 151
21/12/06 17:38:32 INFO InputInfoTracker: remove old batch metadata: 1638792510000 ms
21/12/06 17:38:32 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:32 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:32 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:32 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:32 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:32 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:32 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:32 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:32 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:32 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:32 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:33 INFO JobScheduler: Added jobs for time 1638792513000 ms
21/12/06 17:38:33 INFO JobScheduler: Starting job streaming job 1638792513000 ms.0 from job set of time 1638792513000 ms
21/12/06 17:38:33 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:33 INFO DAGScheduler: Job 93 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000121 s
21/12/06 17:38:33 INFO JobScheduler: Finished job streaming job 1638792513000 ms.0 from job set of time 1638792513000 ms
21/12/06 17:38:33 INFO JobScheduler: Total delay: 0.018 s for time 1638792513000 ms (execution: 0.016 s)
21/12/06 17:38:33 INFO BlockRDD: Removing RDD 152 from persistence list
21/12/06 17:38:33 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[152] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792513000 ms
21/12/06 17:38:33 INFO ReceivedBlockTracker: Deleting batches: 1638792511000 ms
21/12/06 17:38:33 INFO InputInfoTracker: remove old batch metadata: 1638792511000 ms
21/12/06 17:38:33 INFO BlockManager: Removing RDD 152
21/12/06 17:38:34 INFO JobScheduler: Added jobs for time 1638792514000 ms
21/12/06 17:38:34 INFO JobScheduler: Starting job streaming job 1638792514000 ms.0 from job set of time 1638792514000 ms
21/12/06 17:38:34 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:34 INFO DAGScheduler: Job 94 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000239 s
21/12/06 17:38:34 INFO JobScheduler: Finished job streaming job 1638792514000 ms.0 from job set of time 1638792514000 ms
21/12/06 17:38:34 INFO JobScheduler: Total delay: 0.013 s for time 1638792514000 ms (execution: 0.011 s)
21/12/06 17:38:34 INFO BlockRDD: Removing RDD 153 from persistence list
21/12/06 17:38:34 INFO BlockManager: Removing RDD 153
21/12/06 17:38:34 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[153] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792514000 ms
21/12/06 17:38:34 INFO ReceivedBlockTracker: Deleting batches: 1638792512000 ms
21/12/06 17:38:34 INFO InputInfoTracker: remove old batch metadata: 1638792512000 ms
21/12/06 17:38:34 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:34 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:34 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:34 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:34 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:34 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:34 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:34 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:34 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:34 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:34 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:35 INFO JobScheduler: Added jobs for time 1638792515000 ms
21/12/06 17:38:35 INFO JobScheduler: Starting job streaming job 1638792515000 ms.0 from job set of time 1638792515000 ms
21/12/06 17:38:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:35 INFO DAGScheduler: Job 95 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000180 s
21/12/06 17:38:35 INFO JobScheduler: Finished job streaming job 1638792515000 ms.0 from job set of time 1638792515000 ms
21/12/06 17:38:35 INFO JobScheduler: Total delay: 0.014 s for time 1638792515000 ms (execution: 0.012 s)
21/12/06 17:38:35 INFO BlockRDD: Removing RDD 154 from persistence list
21/12/06 17:38:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[154] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792515000 ms
21/12/06 17:38:35 INFO ReceivedBlockTracker: Deleting batches: 1638792513000 ms
21/12/06 17:38:35 INFO InputInfoTracker: remove old batch metadata: 1638792513000 ms
21/12/06 17:38:35 INFO BlockManager: Removing RDD 154
21/12/06 17:38:36 INFO JobScheduler: Added jobs for time 1638792516000 ms
21/12/06 17:38:36 INFO JobScheduler: Starting job streaming job 1638792516000 ms.0 from job set of time 1638792516000 ms
21/12/06 17:38:36 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:36 INFO DAGScheduler: Job 96 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000133 s
21/12/06 17:38:36 INFO JobScheduler: Finished job streaming job 1638792516000 ms.0 from job set of time 1638792516000 ms
21/12/06 17:38:36 INFO JobScheduler: Total delay: 0.031 s for time 1638792516000 ms (execution: 0.024 s)
21/12/06 17:38:36 INFO BlockRDD: Removing RDD 155 from persistence list
21/12/06 17:38:36 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[155] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792516000 ms
21/12/06 17:38:36 INFO ReceivedBlockTracker: Deleting batches: 1638792514000 ms
21/12/06 17:38:36 INFO InputInfoTracker: remove old batch metadata: 1638792514000 ms
21/12/06 17:38:36 INFO BlockManager: Removing RDD 155
21/12/06 17:38:36 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:36 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:36 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:36 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:36 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:36 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:36 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:36 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:36 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:36 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:36 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:37 INFO JobScheduler: Added jobs for time 1638792517000 ms
21/12/06 17:38:37 INFO JobScheduler: Starting job streaming job 1638792517000 ms.0 from job set of time 1638792517000 ms
21/12/06 17:38:37 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:37 INFO DAGScheduler: Job 97 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000427 s
21/12/06 17:38:37 INFO JobScheduler: Finished job streaming job 1638792517000 ms.0 from job set of time 1638792517000 ms
21/12/06 17:38:37 INFO JobScheduler: Total delay: 0.025 s for time 1638792517000 ms (execution: 0.020 s)
21/12/06 17:38:37 INFO BlockRDD: Removing RDD 156 from persistence list
21/12/06 17:38:37 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[156] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792517000 ms
21/12/06 17:38:37 INFO ReceivedBlockTracker: Deleting batches: 1638792515000 ms
21/12/06 17:38:37 INFO InputInfoTracker: remove old batch metadata: 1638792515000 ms
21/12/06 17:38:37 INFO BlockManager: Removing RDD 156
21/12/06 17:38:38 INFO JobScheduler: Added jobs for time 1638792518000 ms
21/12/06 17:38:38 INFO JobScheduler: Starting job streaming job 1638792518000 ms.0 from job set of time 1638792518000 ms
21/12/06 17:38:38 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:38 INFO DAGScheduler: Job 98 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000098 s
21/12/06 17:38:38 INFO JobScheduler: Finished job streaming job 1638792518000 ms.0 from job set of time 1638792518000 ms
21/12/06 17:38:38 INFO JobScheduler: Total delay: 0.012 s for time 1638792518000 ms (execution: 0.010 s)
21/12/06 17:38:38 INFO BlockRDD: Removing RDD 157 from persistence list
21/12/06 17:38:38 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[157] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792518000 ms
21/12/06 17:38:38 INFO ReceivedBlockTracker: Deleting batches: 1638792516000 ms
21/12/06 17:38:38 INFO InputInfoTracker: remove old batch metadata: 1638792516000 ms
21/12/06 17:38:38 INFO BlockManager: Removing RDD 157
21/12/06 17:38:38 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:38 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:38 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:38 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:38 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:38 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:38 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:38 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:38 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:38 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:38 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:38 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:39 INFO JobScheduler: Added jobs for time 1638792519000 ms
21/12/06 17:38:39 INFO JobScheduler: Starting job streaming job 1638792519000 ms.0 from job set of time 1638792519000 ms
21/12/06 17:38:39 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:39 INFO DAGScheduler: Job 99 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000185 s
21/12/06 17:38:39 INFO JobScheduler: Finished job streaming job 1638792519000 ms.0 from job set of time 1638792519000 ms
21/12/06 17:38:39 INFO JobScheduler: Total delay: 0.021 s for time 1638792519000 ms (execution: 0.018 s)
21/12/06 17:38:39 INFO BlockRDD: Removing RDD 158 from persistence list
21/12/06 17:38:39 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[158] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792519000 ms
21/12/06 17:38:39 INFO ReceivedBlockTracker: Deleting batches: 1638792517000 ms
21/12/06 17:38:39 INFO InputInfoTracker: remove old batch metadata: 1638792517000 ms
21/12/06 17:38:39 INFO BlockManager: Removing RDD 158
21/12/06 17:38:40 INFO JobScheduler: Added jobs for time 1638792520000 ms
21/12/06 17:38:40 INFO JobScheduler: Starting job streaming job 1638792520000 ms.0 from job set of time 1638792520000 ms
21/12/06 17:38:40 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:40 INFO DAGScheduler: Job 100 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000081 s
21/12/06 17:38:40 INFO JobScheduler: Finished job streaming job 1638792520000 ms.0 from job set of time 1638792520000 ms
21/12/06 17:38:40 INFO JobScheduler: Total delay: 0.015 s for time 1638792520000 ms (execution: 0.012 s)
21/12/06 17:38:40 INFO BlockRDD: Removing RDD 159 from persistence list
21/12/06 17:38:40 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[159] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792520000 ms
21/12/06 17:38:40 INFO ReceivedBlockTracker: Deleting batches: 1638792518000 ms
21/12/06 17:38:40 INFO BlockManager: Removing RDD 159
21/12/06 17:38:40 INFO InputInfoTracker: remove old batch metadata: 1638792518000 ms
21/12/06 17:38:40 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:40 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:40 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:40 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:40 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:40 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:40 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:40 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:40 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:40 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:40 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:40 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:41 INFO JobScheduler: Added jobs for time 1638792521000 ms
21/12/06 17:38:41 INFO JobScheduler: Starting job streaming job 1638792521000 ms.0 from job set of time 1638792521000 ms
21/12/06 17:38:41 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:41 INFO DAGScheduler: Job 101 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000138 s
21/12/06 17:38:41 INFO JobScheduler: Finished job streaming job 1638792521000 ms.0 from job set of time 1638792521000 ms
21/12/06 17:38:41 INFO JobScheduler: Total delay: 0.025 s for time 1638792521000 ms (execution: 0.022 s)
21/12/06 17:38:41 INFO BlockRDD: Removing RDD 160 from persistence list
21/12/06 17:38:41 INFO BlockManager: Removing RDD 160
21/12/06 17:38:41 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[160] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792521000 ms
21/12/06 17:38:41 INFO ReceivedBlockTracker: Deleting batches: 1638792519000 ms
21/12/06 17:38:41 INFO InputInfoTracker: remove old batch metadata: 1638792519000 ms
21/12/06 17:38:42 INFO JobScheduler: Added jobs for time 1638792522000 ms
21/12/06 17:38:42 INFO JobScheduler: Starting job streaming job 1638792522000 ms.0 from job set of time 1638792522000 ms
21/12/06 17:38:42 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:42 INFO DAGScheduler: Job 102 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000150 s
21/12/06 17:38:42 INFO JobScheduler: Finished job streaming job 1638792522000 ms.0 from job set of time 1638792522000 ms
21/12/06 17:38:42 INFO JobScheduler: Total delay: 0.018 s for time 1638792522000 ms (execution: 0.016 s)
21/12/06 17:38:42 INFO BlockRDD: Removing RDD 161 from persistence list
21/12/06 17:38:42 INFO BlockManager: Removing RDD 161
21/12/06 17:38:42 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[161] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792522000 ms
21/12/06 17:38:42 INFO ReceivedBlockTracker: Deleting batches: 1638792520000 ms
21/12/06 17:38:42 INFO InputInfoTracker: remove old batch metadata: 1638792520000 ms
21/12/06 17:38:42 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:42 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:42 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:42 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:42 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:42 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:42 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:42 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:42 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:42 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:42 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:42 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:43 INFO JobScheduler: Added jobs for time 1638792523000 ms
21/12/06 17:38:43 INFO JobScheduler: Starting job streaming job 1638792523000 ms.0 from job set of time 1638792523000 ms
21/12/06 17:38:43 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:43 INFO DAGScheduler: Job 103 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000121 s
21/12/06 17:38:43 INFO JobScheduler: Finished job streaming job 1638792523000 ms.0 from job set of time 1638792523000 ms
21/12/06 17:38:43 INFO JobScheduler: Total delay: 0.019 s for time 1638792523000 ms (execution: 0.016 s)
21/12/06 17:38:43 INFO BlockRDD: Removing RDD 162 from persistence list
21/12/06 17:38:43 INFO BlockManager: Removing RDD 162
21/12/06 17:38:43 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[162] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792523000 ms
21/12/06 17:38:43 INFO ReceivedBlockTracker: Deleting batches: 1638792521000 ms
21/12/06 17:38:43 INFO InputInfoTracker: remove old batch metadata: 1638792521000 ms
21/12/06 17:38:44 INFO JobScheduler: Added jobs for time 1638792524000 ms
21/12/06 17:38:44 INFO JobScheduler: Starting job streaming job 1638792524000 ms.0 from job set of time 1638792524000 ms
21/12/06 17:38:44 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:44 INFO DAGScheduler: Job 104 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000143 s
21/12/06 17:38:44 INFO JobScheduler: Finished job streaming job 1638792524000 ms.0 from job set of time 1638792524000 ms
21/12/06 17:38:44 INFO JobScheduler: Total delay: 0.019 s for time 1638792524000 ms (execution: 0.018 s)
21/12/06 17:38:44 INFO BlockRDD: Removing RDD 163 from persistence list
21/12/06 17:38:44 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[163] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792524000 ms
21/12/06 17:38:44 INFO ReceivedBlockTracker: Deleting batches: 1638792522000 ms
21/12/06 17:38:44 INFO InputInfoTracker: remove old batch metadata: 1638792522000 ms
21/12/06 17:38:44 INFO BlockManager: Removing RDD 163
21/12/06 17:38:44 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:44 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:44 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:44 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:44 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:44 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:44 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:44 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:44 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:44 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:44 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:44 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:45 INFO JobScheduler: Added jobs for time 1638792525000 ms
21/12/06 17:38:45 INFO JobScheduler: Starting job streaming job 1638792525000 ms.0 from job set of time 1638792525000 ms
21/12/06 17:38:45 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:45 INFO DAGScheduler: Job 105 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000160 s
21/12/06 17:38:45 INFO JobScheduler: Finished job streaming job 1638792525000 ms.0 from job set of time 1638792525000 ms
21/12/06 17:38:45 INFO JobScheduler: Total delay: 0.018 s for time 1638792525000 ms (execution: 0.014 s)
21/12/06 17:38:45 INFO BlockRDD: Removing RDD 164 from persistence list
21/12/06 17:38:45 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[164] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792525000 ms
21/12/06 17:38:45 INFO BlockManager: Removing RDD 164
21/12/06 17:38:45 INFO ReceivedBlockTracker: Deleting batches: 1638792523000 ms
21/12/06 17:38:45 INFO InputInfoTracker: remove old batch metadata: 1638792523000 ms
21/12/06 17:38:46 INFO JobScheduler: Added jobs for time 1638792526000 ms
21/12/06 17:38:46 INFO JobScheduler: Starting job streaming job 1638792526000 ms.0 from job set of time 1638792526000 ms
21/12/06 17:38:46 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:46 INFO DAGScheduler: Job 106 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000433 s
21/12/06 17:38:46 INFO JobScheduler: Finished job streaming job 1638792526000 ms.0 from job set of time 1638792526000 ms
21/12/06 17:38:46 INFO JobScheduler: Total delay: 0.019 s for time 1638792526000 ms (execution: 0.016 s)
21/12/06 17:38:46 INFO BlockRDD: Removing RDD 165 from persistence list
21/12/06 17:38:46 INFO BlockManager: Removing RDD 165
21/12/06 17:38:46 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[165] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792526000 ms
21/12/06 17:38:46 INFO ReceivedBlockTracker: Deleting batches: 1638792524000 ms
21/12/06 17:38:46 INFO InputInfoTracker: remove old batch metadata: 1638792524000 ms
21/12/06 17:38:46 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:46 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:46 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:46 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:46 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:46 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:46 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:46 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:46 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:46 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:46 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:46 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:47 INFO JobScheduler: Added jobs for time 1638792527000 ms
21/12/06 17:38:47 INFO JobScheduler: Starting job streaming job 1638792527000 ms.0 from job set of time 1638792527000 ms
21/12/06 17:38:47 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:47 INFO DAGScheduler: Job 107 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000620 s
21/12/06 17:38:47 INFO JobScheduler: Finished job streaming job 1638792527000 ms.0 from job set of time 1638792527000 ms
21/12/06 17:38:47 INFO JobScheduler: Total delay: 0.019 s for time 1638792527000 ms (execution: 0.017 s)
21/12/06 17:38:47 INFO BlockRDD: Removing RDD 166 from persistence list
21/12/06 17:38:47 INFO BlockManager: Removing RDD 166
21/12/06 17:38:47 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[166] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792527000 ms
21/12/06 17:38:47 INFO ReceivedBlockTracker: Deleting batches: 1638792525000 ms
21/12/06 17:38:47 INFO InputInfoTracker: remove old batch metadata: 1638792525000 ms
21/12/06 17:38:48 INFO JobScheduler: Added jobs for time 1638792528000 ms
21/12/06 17:38:48 INFO JobScheduler: Starting job streaming job 1638792528000 ms.0 from job set of time 1638792528000 ms
21/12/06 17:38:48 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:48 INFO DAGScheduler: Job 108 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000103 s
21/12/06 17:38:48 INFO JobScheduler: Finished job streaming job 1638792528000 ms.0 from job set of time 1638792528000 ms
21/12/06 17:38:48 INFO JobScheduler: Total delay: 0.043 s for time 1638792528000 ms (execution: 0.040 s)
21/12/06 17:38:48 INFO BlockRDD: Removing RDD 167 from persistence list
21/12/06 17:38:48 INFO BlockManager: Removing RDD 167
21/12/06 17:38:48 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[167] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792528000 ms
21/12/06 17:38:48 INFO ReceivedBlockTracker: Deleting batches: 1638792526000 ms
21/12/06 17:38:48 INFO InputInfoTracker: remove old batch metadata: 1638792526000 ms
21/12/06 17:38:48 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:48 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:48 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:48 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:48 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:48 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:48 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:48 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:48 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:48 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:48 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:48 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:49 INFO JobScheduler: Added jobs for time 1638792529000 ms
21/12/06 17:38:49 INFO JobScheduler: Starting job streaming job 1638792529000 ms.0 from job set of time 1638792529000 ms
21/12/06 17:38:49 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:49 INFO DAGScheduler: Job 109 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000125 s
21/12/06 17:38:49 INFO JobScheduler: Finished job streaming job 1638792529000 ms.0 from job set of time 1638792529000 ms
21/12/06 17:38:49 INFO JobScheduler: Total delay: 0.015 s for time 1638792529000 ms (execution: 0.013 s)
21/12/06 17:38:49 INFO BlockRDD: Removing RDD 168 from persistence list
21/12/06 17:38:49 INFO BlockManager: Removing RDD 168
21/12/06 17:38:49 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[168] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792529000 ms
21/12/06 17:38:49 INFO ReceivedBlockTracker: Deleting batches: 1638792527000 ms
21/12/06 17:38:49 INFO InputInfoTracker: remove old batch metadata: 1638792527000 ms
21/12/06 17:38:50 INFO JobScheduler: Added jobs for time 1638792530000 ms
21/12/06 17:38:50 INFO JobScheduler: Starting job streaming job 1638792530000 ms.0 from job set of time 1638792530000 ms
21/12/06 17:38:50 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:50 INFO DAGScheduler: Job 110 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000160 s
21/12/06 17:38:50 INFO JobScheduler: Finished job streaming job 1638792530000 ms.0 from job set of time 1638792530000 ms
21/12/06 17:38:50 INFO JobScheduler: Total delay: 0.013 s for time 1638792530000 ms (execution: 0.011 s)
21/12/06 17:38:50 INFO BlockRDD: Removing RDD 169 from persistence list
21/12/06 17:38:50 INFO BlockManager: Removing RDD 169
21/12/06 17:38:50 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[169] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792530000 ms
21/12/06 17:38:50 INFO ReceivedBlockTracker: Deleting batches: 1638792528000 ms
21/12/06 17:38:50 INFO InputInfoTracker: remove old batch metadata: 1638792528000 ms
21/12/06 17:38:50 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:50 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:50 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:50 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:50 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:50 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:50 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:50 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:50 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:50 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:50 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:50 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:51 INFO JobScheduler: Added jobs for time 1638792531000 ms
21/12/06 17:38:51 INFO JobScheduler: Starting job streaming job 1638792531000 ms.0 from job set of time 1638792531000 ms
21/12/06 17:38:51 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:51 INFO DAGScheduler: Job 111 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000207 s
21/12/06 17:38:51 INFO JobScheduler: Finished job streaming job 1638792531000 ms.0 from job set of time 1638792531000 ms
21/12/06 17:38:51 INFO JobScheduler: Total delay: 0.015 s for time 1638792531000 ms (execution: 0.014 s)
21/12/06 17:38:51 INFO BlockRDD: Removing RDD 170 from persistence list
21/12/06 17:38:51 INFO BlockManager: Removing RDD 170
21/12/06 17:38:51 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[170] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792531000 ms
21/12/06 17:38:51 INFO ReceivedBlockTracker: Deleting batches: 1638792529000 ms
21/12/06 17:38:51 INFO InputInfoTracker: remove old batch metadata: 1638792529000 ms
21/12/06 17:38:52 INFO JobScheduler: Added jobs for time 1638792532000 ms
21/12/06 17:38:52 INFO JobScheduler: Starting job streaming job 1638792532000 ms.0 from job set of time 1638792532000 ms
21/12/06 17:38:52 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:52 INFO DAGScheduler: Job 112 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000690 s
21/12/06 17:38:52 INFO JobScheduler: Finished job streaming job 1638792532000 ms.0 from job set of time 1638792532000 ms
21/12/06 17:38:52 INFO JobScheduler: Total delay: 0.028 s for time 1638792532000 ms (execution: 0.024 s)
21/12/06 17:38:52 INFO BlockRDD: Removing RDD 171 from persistence list
21/12/06 17:38:52 INFO BlockManager: Removing RDD 171
21/12/06 17:38:52 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[171] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792532000 ms
21/12/06 17:38:52 INFO ReceivedBlockTracker: Deleting batches: 1638792530000 ms
21/12/06 17:38:52 INFO InputInfoTracker: remove old batch metadata: 1638792530000 ms
21/12/06 17:38:52 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:52 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:52 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:52 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:52 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:52 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:52 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:52 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:52 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:52 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:52 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:52 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:53 INFO JobScheduler: Added jobs for time 1638792533000 ms
21/12/06 17:38:53 INFO JobScheduler: Starting job streaming job 1638792533000 ms.0 from job set of time 1638792533000 ms
21/12/06 17:38:53 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:53 INFO DAGScheduler: Job 113 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000087 s
21/12/06 17:38:53 INFO JobScheduler: Finished job streaming job 1638792533000 ms.0 from job set of time 1638792533000 ms
21/12/06 17:38:53 INFO JobScheduler: Total delay: 0.011 s for time 1638792533000 ms (execution: 0.009 s)
21/12/06 17:38:53 INFO BlockRDD: Removing RDD 172 from persistence list
21/12/06 17:38:53 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[172] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792533000 ms
21/12/06 17:38:53 INFO BlockManager: Removing RDD 172
21/12/06 17:38:53 INFO ReceivedBlockTracker: Deleting batches: 1638792531000 ms
21/12/06 17:38:53 INFO InputInfoTracker: remove old batch metadata: 1638792531000 ms
21/12/06 17:38:54 INFO JobScheduler: Added jobs for time 1638792534000 ms
21/12/06 17:38:54 INFO JobScheduler: Starting job streaming job 1638792534000 ms.0 from job set of time 1638792534000 ms
21/12/06 17:38:54 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:54 INFO DAGScheduler: Job 114 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000099 s
21/12/06 17:38:54 INFO JobScheduler: Finished job streaming job 1638792534000 ms.0 from job set of time 1638792534000 ms
21/12/06 17:38:54 INFO JobScheduler: Total delay: 0.015 s for time 1638792534000 ms (execution: 0.012 s)
21/12/06 17:38:54 INFO BlockRDD: Removing RDD 173 from persistence list
21/12/06 17:38:54 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[173] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792534000 ms
21/12/06 17:38:54 INFO ReceivedBlockTracker: Deleting batches: 1638792532000 ms
21/12/06 17:38:54 INFO BlockManager: Removing RDD 173
21/12/06 17:38:54 INFO InputInfoTracker: remove old batch metadata: 1638792532000 ms
21/12/06 17:38:54 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:54 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:54 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:54 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:54 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:54 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:54 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:54 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:54 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:54 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:54 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:54 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:55 INFO JobScheduler: Added jobs for time 1638792535000 ms
21/12/06 17:38:55 INFO JobScheduler: Starting job streaming job 1638792535000 ms.0 from job set of time 1638792535000 ms
21/12/06 17:38:55 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:55 INFO DAGScheduler: Job 115 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000111 s
21/12/06 17:38:55 INFO JobScheduler: Finished job streaming job 1638792535000 ms.0 from job set of time 1638792535000 ms
21/12/06 17:38:55 INFO JobScheduler: Total delay: 0.011 s for time 1638792535000 ms (execution: 0.009 s)
21/12/06 17:38:55 INFO BlockRDD: Removing RDD 174 from persistence list
21/12/06 17:38:55 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[174] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792535000 ms
21/12/06 17:38:55 INFO ReceivedBlockTracker: Deleting batches: 1638792533000 ms
21/12/06 17:38:55 INFO InputInfoTracker: remove old batch metadata: 1638792533000 ms
21/12/06 17:38:55 INFO BlockManager: Removing RDD 174
21/12/06 17:38:56 INFO JobScheduler: Added jobs for time 1638792536000 ms
21/12/06 17:38:56 INFO JobScheduler: Starting job streaming job 1638792536000 ms.0 from job set of time 1638792536000 ms
21/12/06 17:38:56 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:56 INFO DAGScheduler: Job 116 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000087 s
21/12/06 17:38:56 INFO JobScheduler: Finished job streaming job 1638792536000 ms.0 from job set of time 1638792536000 ms
21/12/06 17:38:56 INFO JobScheduler: Total delay: 0.011 s for time 1638792536000 ms (execution: 0.010 s)
21/12/06 17:38:56 INFO BlockRDD: Removing RDD 175 from persistence list
21/12/06 17:38:56 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[175] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792536000 ms
21/12/06 17:38:56 INFO ReceivedBlockTracker: Deleting batches: 1638792534000 ms
21/12/06 17:38:56 INFO InputInfoTracker: remove old batch metadata: 1638792534000 ms
21/12/06 17:38:56 INFO BlockManager: Removing RDD 175
21/12/06 17:38:56 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:56 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:56 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:56 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:56 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:56 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:56 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:56 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:56 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:56 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:56 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:56 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:57 INFO JobScheduler: Added jobs for time 1638792537000 ms
21/12/06 17:38:57 INFO JobScheduler: Starting job streaming job 1638792537000 ms.0 from job set of time 1638792537000 ms
21/12/06 17:38:57 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:57 INFO DAGScheduler: Job 117 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000089 s
21/12/06 17:38:57 INFO JobScheduler: Finished job streaming job 1638792537000 ms.0 from job set of time 1638792537000 ms
21/12/06 17:38:57 INFO JobScheduler: Total delay: 0.016 s for time 1638792537000 ms (execution: 0.013 s)
21/12/06 17:38:57 INFO BlockRDD: Removing RDD 176 from persistence list
21/12/06 17:38:57 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[176] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792537000 ms
21/12/06 17:38:57 INFO ReceivedBlockTracker: Deleting batches: 1638792535000 ms
21/12/06 17:38:57 INFO InputInfoTracker: remove old batch metadata: 1638792535000 ms
21/12/06 17:38:57 INFO BlockManager: Removing RDD 176
21/12/06 17:38:58 INFO JobScheduler: Added jobs for time 1638792538000 ms
21/12/06 17:38:58 INFO JobScheduler: Starting job streaming job 1638792538000 ms.0 from job set of time 1638792538000 ms
21/12/06 17:38:58 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:58 INFO DAGScheduler: Job 118 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000082 s
21/12/06 17:38:58 INFO JobScheduler: Finished job streaming job 1638792538000 ms.0 from job set of time 1638792538000 ms
21/12/06 17:38:58 INFO JobScheduler: Total delay: 0.012 s for time 1638792538000 ms (execution: 0.011 s)
21/12/06 17:38:58 INFO BlockRDD: Removing RDD 177 from persistence list
21/12/06 17:38:58 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[177] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792538000 ms
21/12/06 17:38:58 INFO ReceivedBlockTracker: Deleting batches: 1638792536000 ms
21/12/06 17:38:58 INFO InputInfoTracker: remove old batch metadata: 1638792536000 ms
21/12/06 17:38:58 INFO BlockManager: Removing RDD 177
21/12/06 17:38:58 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:38:58 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:38:58 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:38:58 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:38:58 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:38:58 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:38:58 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:38:58 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:38:58 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:38:58 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:38:58 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:38:58 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:38:59 INFO JobScheduler: Added jobs for time 1638792539000 ms
21/12/06 17:38:59 INFO JobScheduler: Starting job streaming job 1638792539000 ms.0 from job set of time 1638792539000 ms
21/12/06 17:38:59 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:38:59 INFO DAGScheduler: Job 119 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000141 s
21/12/06 17:38:59 INFO JobScheduler: Finished job streaming job 1638792539000 ms.0 from job set of time 1638792539000 ms
21/12/06 17:38:59 INFO JobScheduler: Total delay: 0.014 s for time 1638792539000 ms (execution: 0.012 s)
21/12/06 17:38:59 INFO BlockRDD: Removing RDD 178 from persistence list
21/12/06 17:38:59 INFO BlockManager: Removing RDD 178
21/12/06 17:38:59 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[178] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792539000 ms
21/12/06 17:38:59 INFO ReceivedBlockTracker: Deleting batches: 1638792537000 ms
21/12/06 17:38:59 INFO InputInfoTracker: remove old batch metadata: 1638792537000 ms
21/12/06 17:39:00 INFO JobScheduler: Added jobs for time 1638792540000 ms
21/12/06 17:39:00 INFO JobScheduler: Starting job streaming job 1638792540000 ms.0 from job set of time 1638792540000 ms
21/12/06 17:39:00 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:00 INFO DAGScheduler: Job 120 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000083 s
21/12/06 17:39:00 INFO JobScheduler: Finished job streaming job 1638792540000 ms.0 from job set of time 1638792540000 ms
21/12/06 17:39:00 INFO JobScheduler: Total delay: 0.025 s for time 1638792540000 ms (execution: 0.020 s)
21/12/06 17:39:00 INFO BlockRDD: Removing RDD 179 from persistence list
21/12/06 17:39:00 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[179] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792540000 ms
21/12/06 17:39:00 INFO ReceivedBlockTracker: Deleting batches: 1638792538000 ms
21/12/06 17:39:00 INFO InputInfoTracker: remove old batch metadata: 1638792538000 ms
21/12/06 17:39:00 INFO BlockManager: Removing RDD 179
21/12/06 17:39:00 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:00 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:00 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:00 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:00 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:00 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:00 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:00 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:00 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:00 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:00 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:00 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:01 INFO JobScheduler: Added jobs for time 1638792541000 ms
21/12/06 17:39:01 INFO JobScheduler: Starting job streaming job 1638792541000 ms.0 from job set of time 1638792541000 ms
21/12/06 17:39:01 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:01 INFO DAGScheduler: Job 121 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000084 s
21/12/06 17:39:01 INFO JobScheduler: Finished job streaming job 1638792541000 ms.0 from job set of time 1638792541000 ms
21/12/06 17:39:01 INFO JobScheduler: Total delay: 0.014 s for time 1638792541000 ms (execution: 0.011 s)
21/12/06 17:39:01 INFO BlockRDD: Removing RDD 180 from persistence list
21/12/06 17:39:01 INFO BlockManager: Removing RDD 180
21/12/06 17:39:01 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[180] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792541000 ms
21/12/06 17:39:01 INFO ReceivedBlockTracker: Deleting batches: 1638792539000 ms
21/12/06 17:39:01 INFO InputInfoTracker: remove old batch metadata: 1638792539000 ms
21/12/06 17:39:02 INFO JobScheduler: Added jobs for time 1638792542000 ms
21/12/06 17:39:02 INFO JobScheduler: Starting job streaming job 1638792542000 ms.0 from job set of time 1638792542000 ms
21/12/06 17:39:02 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:02 INFO DAGScheduler: Job 122 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000076 s
21/12/06 17:39:02 INFO JobScheduler: Finished job streaming job 1638792542000 ms.0 from job set of time 1638792542000 ms
21/12/06 17:39:02 INFO JobScheduler: Total delay: 0.014 s for time 1638792542000 ms (execution: 0.012 s)
21/12/06 17:39:02 INFO BlockRDD: Removing RDD 181 from persistence list
21/12/06 17:39:02 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[181] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792542000 ms
21/12/06 17:39:02 INFO ReceivedBlockTracker: Deleting batches: 1638792540000 ms
21/12/06 17:39:02 INFO InputInfoTracker: remove old batch metadata: 1638792540000 ms
21/12/06 17:39:02 INFO BlockManager: Removing RDD 181
21/12/06 17:39:02 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:02 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:02 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:02 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:02 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:02 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:02 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:02 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:02 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:02 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:02 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:02 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:03 INFO JobScheduler: Added jobs for time 1638792543000 ms
21/12/06 17:39:03 INFO JobScheduler: Starting job streaming job 1638792543000 ms.0 from job set of time 1638792543000 ms
21/12/06 17:39:03 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:03 INFO DAGScheduler: Job 123 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000338 s
21/12/06 17:39:03 INFO JobScheduler: Finished job streaming job 1638792543000 ms.0 from job set of time 1638792543000 ms
21/12/06 17:39:03 INFO JobScheduler: Total delay: 0.014 s for time 1638792543000 ms (execution: 0.011 s)
21/12/06 17:39:03 INFO BlockRDD: Removing RDD 182 from persistence list
21/12/06 17:39:03 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[182] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792543000 ms
21/12/06 17:39:03 INFO BlockManager: Removing RDD 182
21/12/06 17:39:03 INFO ReceivedBlockTracker: Deleting batches: 1638792541000 ms
21/12/06 17:39:03 INFO InputInfoTracker: remove old batch metadata: 1638792541000 ms
21/12/06 17:39:04 INFO JobScheduler: Added jobs for time 1638792544000 ms
21/12/06 17:39:04 INFO JobScheduler: Starting job streaming job 1638792544000 ms.0 from job set of time 1638792544000 ms
21/12/06 17:39:04 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:04 INFO DAGScheduler: Job 124 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000426 s
21/12/06 17:39:04 INFO JobScheduler: Finished job streaming job 1638792544000 ms.0 from job set of time 1638792544000 ms
21/12/06 17:39:04 INFO JobScheduler: Total delay: 0.021 s for time 1638792544000 ms (execution: 0.019 s)
21/12/06 17:39:04 INFO BlockRDD: Removing RDD 183 from persistence list
21/12/06 17:39:04 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[183] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792544000 ms
21/12/06 17:39:04 INFO ReceivedBlockTracker: Deleting batches: 1638792542000 ms
21/12/06 17:39:04 INFO InputInfoTracker: remove old batch metadata: 1638792542000 ms
21/12/06 17:39:04 INFO BlockManager: Removing RDD 183
21/12/06 17:39:04 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:04 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:04 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:04 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:04 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:04 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:04 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:04 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:04 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:04 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:04 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:04 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:05 INFO JobScheduler: Added jobs for time 1638792545000 ms
21/12/06 17:39:05 INFO JobScheduler: Starting job streaming job 1638792545000 ms.0 from job set of time 1638792545000 ms
21/12/06 17:39:05 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:05 INFO DAGScheduler: Job 125 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000161 s
21/12/06 17:39:05 INFO JobScheduler: Finished job streaming job 1638792545000 ms.0 from job set of time 1638792545000 ms
21/12/06 17:39:05 INFO JobScheduler: Total delay: 0.016 s for time 1638792545000 ms (execution: 0.015 s)
21/12/06 17:39:05 INFO BlockRDD: Removing RDD 184 from persistence list
21/12/06 17:39:05 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[184] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792545000 ms
21/12/06 17:39:05 INFO ReceivedBlockTracker: Deleting batches: 1638792543000 ms
21/12/06 17:39:05 INFO InputInfoTracker: remove old batch metadata: 1638792543000 ms
21/12/06 17:39:05 INFO BlockManager: Removing RDD 184
21/12/06 17:39:06 INFO JobScheduler: Added jobs for time 1638792546000 ms
21/12/06 17:39:06 INFO JobScheduler: Starting job streaming job 1638792546000 ms.0 from job set of time 1638792546000 ms
21/12/06 17:39:06 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:06 INFO DAGScheduler: Job 126 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000207 s
21/12/06 17:39:06 INFO JobScheduler: Finished job streaming job 1638792546000 ms.0 from job set of time 1638792546000 ms
21/12/06 17:39:06 INFO JobScheduler: Total delay: 0.029 s for time 1638792546000 ms (execution: 0.025 s)
21/12/06 17:39:06 INFO BlockRDD: Removing RDD 185 from persistence list
21/12/06 17:39:06 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[185] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792546000 ms
21/12/06 17:39:06 INFO ReceivedBlockTracker: Deleting batches: 1638792544000 ms
21/12/06 17:39:06 INFO InputInfoTracker: remove old batch metadata: 1638792544000 ms
21/12/06 17:39:06 INFO BlockManager: Removing RDD 185
21/12/06 17:39:06 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:06 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:06 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:06 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:06 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:06 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:06 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:06 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:06 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:06 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:06 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:06 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:07 INFO JobScheduler: Added jobs for time 1638792547000 ms
21/12/06 17:39:07 INFO JobScheduler: Starting job streaming job 1638792547000 ms.0 from job set of time 1638792547000 ms
21/12/06 17:39:07 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:07 INFO DAGScheduler: Job 127 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000238 s
21/12/06 17:39:07 INFO JobScheduler: Finished job streaming job 1638792547000 ms.0 from job set of time 1638792547000 ms
21/12/06 17:39:07 INFO JobScheduler: Total delay: 0.015 s for time 1638792547000 ms (execution: 0.013 s)
21/12/06 17:39:07 INFO BlockRDD: Removing RDD 186 from persistence list
21/12/06 17:39:07 INFO BlockManager: Removing RDD 186
21/12/06 17:39:07 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[186] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792547000 ms
21/12/06 17:39:07 INFO ReceivedBlockTracker: Deleting batches: 1638792545000 ms
21/12/06 17:39:07 INFO InputInfoTracker: remove old batch metadata: 1638792545000 ms
21/12/06 17:39:08 INFO JobScheduler: Added jobs for time 1638792548000 ms
21/12/06 17:39:08 INFO JobScheduler: Starting job streaming job 1638792548000 ms.0 from job set of time 1638792548000 ms
21/12/06 17:39:08 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:08 INFO DAGScheduler: Job 128 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000428 s
21/12/06 17:39:08 INFO JobScheduler: Finished job streaming job 1638792548000 ms.0 from job set of time 1638792548000 ms
21/12/06 17:39:08 INFO JobScheduler: Total delay: 0.017 s for time 1638792548000 ms (execution: 0.015 s)
21/12/06 17:39:08 INFO BlockRDD: Removing RDD 187 from persistence list
21/12/06 17:39:08 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[187] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792548000 ms
21/12/06 17:39:08 INFO ReceivedBlockTracker: Deleting batches: 1638792546000 ms
21/12/06 17:39:08 INFO InputInfoTracker: remove old batch metadata: 1638792546000 ms
21/12/06 17:39:08 INFO BlockManager: Removing RDD 187
21/12/06 17:39:08 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:08 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:08 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:08 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:08 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:08 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:08 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:08 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:08 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:08 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:08 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:08 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:09 INFO JobScheduler: Added jobs for time 1638792549000 ms
21/12/06 17:39:09 INFO JobScheduler: Starting job streaming job 1638792549000 ms.0 from job set of time 1638792549000 ms
21/12/06 17:39:09 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:09 INFO DAGScheduler: Job 129 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000104 s
21/12/06 17:39:09 INFO JobScheduler: Finished job streaming job 1638792549000 ms.0 from job set of time 1638792549000 ms
21/12/06 17:39:09 INFO JobScheduler: Total delay: 0.011 s for time 1638792549000 ms (execution: 0.010 s)
21/12/06 17:39:09 INFO BlockRDD: Removing RDD 188 from persistence list
21/12/06 17:39:09 INFO BlockManager: Removing RDD 188
21/12/06 17:39:09 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[188] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792549000 ms
21/12/06 17:39:09 INFO ReceivedBlockTracker: Deleting batches: 1638792547000 ms
21/12/06 17:39:09 INFO InputInfoTracker: remove old batch metadata: 1638792547000 ms
21/12/06 17:39:10 INFO JobScheduler: Added jobs for time 1638792550000 ms
21/12/06 17:39:10 INFO JobScheduler: Starting job streaming job 1638792550000 ms.0 from job set of time 1638792550000 ms
21/12/06 17:39:10 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:10 INFO DAGScheduler: Job 130 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000088 s
21/12/06 17:39:10 INFO JobScheduler: Finished job streaming job 1638792550000 ms.0 from job set of time 1638792550000 ms
21/12/06 17:39:10 INFO JobScheduler: Total delay: 0.014 s for time 1638792550000 ms (execution: 0.013 s)
21/12/06 17:39:10 INFO BlockRDD: Removing RDD 189 from persistence list
21/12/06 17:39:10 INFO BlockManager: Removing RDD 189
21/12/06 17:39:10 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[189] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792550000 ms
21/12/06 17:39:10 INFO ReceivedBlockTracker: Deleting batches: 1638792548000 ms
21/12/06 17:39:10 INFO InputInfoTracker: remove old batch metadata: 1638792548000 ms
21/12/06 17:39:10 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:10 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:10 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:10 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:10 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:10 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:10 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:10 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:10 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:10 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:10 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:10 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:11 INFO JobScheduler: Added jobs for time 1638792551000 ms
21/12/06 17:39:11 INFO JobScheduler: Starting job streaming job 1638792551000 ms.0 from job set of time 1638792551000 ms
21/12/06 17:39:11 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:11 INFO DAGScheduler: Job 131 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000268 s
21/12/06 17:39:11 INFO JobScheduler: Finished job streaming job 1638792551000 ms.0 from job set of time 1638792551000 ms
21/12/06 17:39:11 INFO JobScheduler: Total delay: 0.038 s for time 1638792551000 ms (execution: 0.033 s)
21/12/06 17:39:11 INFO BlockRDD: Removing RDD 190 from persistence list
21/12/06 17:39:11 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[190] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792551000 ms
21/12/06 17:39:11 INFO ReceivedBlockTracker: Deleting batches: 1638792549000 ms
21/12/06 17:39:11 INFO InputInfoTracker: remove old batch metadata: 1638792549000 ms
21/12/06 17:39:11 INFO BlockManager: Removing RDD 190
21/12/06 17:39:12 INFO JobScheduler: Added jobs for time 1638792552000 ms
21/12/06 17:39:12 INFO JobScheduler: Starting job streaming job 1638792552000 ms.0 from job set of time 1638792552000 ms
21/12/06 17:39:12 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:12 INFO DAGScheduler: Job 132 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000684 s
21/12/06 17:39:12 INFO JobScheduler: Finished job streaming job 1638792552000 ms.0 from job set of time 1638792552000 ms
21/12/06 17:39:12 INFO JobScheduler: Total delay: 0.019 s for time 1638792552000 ms (execution: 0.018 s)
21/12/06 17:39:12 INFO BlockRDD: Removing RDD 191 from persistence list
21/12/06 17:39:12 INFO BlockManager: Removing RDD 191
21/12/06 17:39:12 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[191] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792552000 ms
21/12/06 17:39:12 INFO ReceivedBlockTracker: Deleting batches: 1638792550000 ms
21/12/06 17:39:12 INFO InputInfoTracker: remove old batch metadata: 1638792550000 ms
21/12/06 17:39:12 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:12 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:12 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:12 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:12 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:12 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:12 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:12 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:12 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:12 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:12 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:12 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:13 INFO JobScheduler: Added jobs for time 1638792553000 ms
21/12/06 17:39:13 INFO JobScheduler: Starting job streaming job 1638792553000 ms.0 from job set of time 1638792553000 ms
21/12/06 17:39:13 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:13 INFO DAGScheduler: Job 133 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000106 s
21/12/06 17:39:13 INFO JobScheduler: Finished job streaming job 1638792553000 ms.0 from job set of time 1638792553000 ms
21/12/06 17:39:13 INFO JobScheduler: Total delay: 0.030 s for time 1638792553000 ms (execution: 0.026 s)
21/12/06 17:39:13 INFO BlockRDD: Removing RDD 192 from persistence list
21/12/06 17:39:13 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[192] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792553000 ms
21/12/06 17:39:13 INFO ReceivedBlockTracker: Deleting batches: 1638792551000 ms
21/12/06 17:39:13 INFO InputInfoTracker: remove old batch metadata: 1638792551000 ms
21/12/06 17:39:13 INFO BlockManager: Removing RDD 192
21/12/06 17:39:14 INFO JobScheduler: Added jobs for time 1638792554000 ms
21/12/06 17:39:14 INFO JobScheduler: Starting job streaming job 1638792554000 ms.0 from job set of time 1638792554000 ms
21/12/06 17:39:14 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:14 INFO DAGScheduler: Job 134 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000075 s
21/12/06 17:39:14 INFO JobScheduler: Finished job streaming job 1638792554000 ms.0 from job set of time 1638792554000 ms
21/12/06 17:39:14 INFO JobScheduler: Total delay: 0.013 s for time 1638792554000 ms (execution: 0.011 s)
21/12/06 17:39:14 INFO BlockRDD: Removing RDD 193 from persistence list
21/12/06 17:39:14 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[193] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792554000 ms
21/12/06 17:39:14 INFO ReceivedBlockTracker: Deleting batches: 1638792552000 ms
21/12/06 17:39:14 INFO InputInfoTracker: remove old batch metadata: 1638792552000 ms
21/12/06 17:39:14 INFO BlockManager: Removing RDD 193
21/12/06 17:39:14 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:14 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:14 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:14 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:14 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:14 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:14 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:14 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:14 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:14 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:14 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:14 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:15 INFO JobScheduler: Added jobs for time 1638792555000 ms
21/12/06 17:39:15 INFO JobScheduler: Starting job streaming job 1638792555000 ms.0 from job set of time 1638792555000 ms
21/12/06 17:39:15 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:15 INFO DAGScheduler: Job 135 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000093 s
21/12/06 17:39:15 INFO JobScheduler: Finished job streaming job 1638792555000 ms.0 from job set of time 1638792555000 ms
21/12/06 17:39:15 INFO JobScheduler: Total delay: 0.011 s for time 1638792555000 ms (execution: 0.009 s)
21/12/06 17:39:15 INFO BlockRDD: Removing RDD 194 from persistence list
21/12/06 17:39:15 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[194] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792555000 ms
21/12/06 17:39:15 INFO ReceivedBlockTracker: Deleting batches: 1638792553000 ms
21/12/06 17:39:15 INFO BlockManager: Removing RDD 194
21/12/06 17:39:15 INFO InputInfoTracker: remove old batch metadata: 1638792553000 ms
21/12/06 17:39:16 INFO JobScheduler: Added jobs for time 1638792556000 ms
21/12/06 17:39:16 INFO JobScheduler: Starting job streaming job 1638792556000 ms.0 from job set of time 1638792556000 ms
21/12/06 17:39:16 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:16 INFO DAGScheduler: Job 136 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000097 s
21/12/06 17:39:16 INFO JobScheduler: Finished job streaming job 1638792556000 ms.0 from job set of time 1638792556000 ms
21/12/06 17:39:16 INFO JobScheduler: Total delay: 0.012 s for time 1638792556000 ms (execution: 0.010 s)
21/12/06 17:39:16 INFO BlockRDD: Removing RDD 195 from persistence list
21/12/06 17:39:16 INFO BlockManager: Removing RDD 195
21/12/06 17:39:16 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[195] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792556000 ms
21/12/06 17:39:16 INFO ReceivedBlockTracker: Deleting batches: 1638792554000 ms
21/12/06 17:39:16 INFO InputInfoTracker: remove old batch metadata: 1638792554000 ms
21/12/06 17:39:16 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:16 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:16 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:16 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:16 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:16 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:16 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:16 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:16 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:16 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:16 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:16 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:17 INFO JobScheduler: Added jobs for time 1638792557000 ms
21/12/06 17:39:17 INFO JobScheduler: Starting job streaming job 1638792557000 ms.0 from job set of time 1638792557000 ms
21/12/06 17:39:17 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:17 INFO DAGScheduler: Job 137 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000090 s
21/12/06 17:39:17 INFO JobScheduler: Finished job streaming job 1638792557000 ms.0 from job set of time 1638792557000 ms
21/12/06 17:39:17 INFO JobScheduler: Total delay: 0.011 s for time 1638792557000 ms (execution: 0.009 s)
21/12/06 17:39:17 INFO BlockRDD: Removing RDD 196 from persistence list
21/12/06 17:39:17 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[196] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792557000 ms
21/12/06 17:39:17 INFO ReceivedBlockTracker: Deleting batches: 1638792555000 ms
21/12/06 17:39:17 INFO InputInfoTracker: remove old batch metadata: 1638792555000 ms
21/12/06 17:39:17 INFO BlockManager: Removing RDD 196
21/12/06 17:39:18 INFO JobScheduler: Added jobs for time 1638792558000 ms
21/12/06 17:39:18 INFO JobScheduler: Starting job streaming job 1638792558000 ms.0 from job set of time 1638792558000 ms
21/12/06 17:39:18 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:18 INFO DAGScheduler: Job 138 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000137 s
21/12/06 17:39:18 INFO JobScheduler: Finished job streaming job 1638792558000 ms.0 from job set of time 1638792558000 ms
21/12/06 17:39:18 INFO JobScheduler: Total delay: 0.013 s for time 1638792558000 ms (execution: 0.012 s)
21/12/06 17:39:18 INFO BlockRDD: Removing RDD 197 from persistence list
21/12/06 17:39:18 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[197] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792558000 ms
21/12/06 17:39:18 INFO ReceivedBlockTracker: Deleting batches: 1638792556000 ms
21/12/06 17:39:18 INFO InputInfoTracker: remove old batch metadata: 1638792556000 ms
21/12/06 17:39:18 INFO BlockManager: Removing RDD 197
21/12/06 17:39:18 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:18 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:18 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:18 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:18 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:18 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:18 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:18 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:18 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:18 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:18 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:18 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:19 INFO JobScheduler: Added jobs for time 1638792559000 ms
21/12/06 17:39:19 INFO JobScheduler: Starting job streaming job 1638792559000 ms.0 from job set of time 1638792559000 ms
21/12/06 17:39:19 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:19 INFO DAGScheduler: Job 139 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000088 s
21/12/06 17:39:19 INFO JobScheduler: Finished job streaming job 1638792559000 ms.0 from job set of time 1638792559000 ms
21/12/06 17:39:19 INFO JobScheduler: Total delay: 0.020 s for time 1638792559000 ms (execution: 0.015 s)
21/12/06 17:39:19 INFO BlockRDD: Removing RDD 198 from persistence list
21/12/06 17:39:19 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[198] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792559000 ms
21/12/06 17:39:19 INFO ReceivedBlockTracker: Deleting batches: 1638792557000 ms
21/12/06 17:39:19 INFO InputInfoTracker: remove old batch metadata: 1638792557000 ms
21/12/06 17:39:19 INFO BlockManager: Removing RDD 198
21/12/06 17:39:20 INFO JobScheduler: Added jobs for time 1638792560000 ms
21/12/06 17:39:20 INFO JobScheduler: Starting job streaming job 1638792560000 ms.0 from job set of time 1638792560000 ms
21/12/06 17:39:20 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:20 INFO DAGScheduler: Job 140 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000185 s
21/12/06 17:39:20 INFO JobScheduler: Finished job streaming job 1638792560000 ms.0 from job set of time 1638792560000 ms
21/12/06 17:39:20 INFO JobScheduler: Total delay: 0.016 s for time 1638792560000 ms (execution: 0.014 s)
21/12/06 17:39:20 INFO BlockRDD: Removing RDD 199 from persistence list
21/12/06 17:39:20 INFO BlockManager: Removing RDD 199
21/12/06 17:39:20 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[199] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792560000 ms
21/12/06 17:39:20 INFO ReceivedBlockTracker: Deleting batches: 1638792558000 ms
21/12/06 17:39:20 INFO InputInfoTracker: remove old batch metadata: 1638792558000 ms
21/12/06 17:39:20 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:20 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:20 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:20 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:20 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:20 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:20 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:20 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:20 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:20 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:20 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:20 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:21 INFO JobScheduler: Added jobs for time 1638792561000 ms
21/12/06 17:39:21 INFO JobScheduler: Starting job streaming job 1638792561000 ms.0 from job set of time 1638792561000 ms
21/12/06 17:39:21 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:21 INFO DAGScheduler: Job 141 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000340 s
21/12/06 17:39:21 INFO JobScheduler: Finished job streaming job 1638792561000 ms.0 from job set of time 1638792561000 ms
21/12/06 17:39:21 INFO JobScheduler: Total delay: 0.038 s for time 1638792561000 ms (execution: 0.034 s)
21/12/06 17:39:21 INFO BlockRDD: Removing RDD 200 from persistence list
21/12/06 17:39:21 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[200] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792561000 ms
21/12/06 17:39:21 INFO ReceivedBlockTracker: Deleting batches: 1638792559000 ms
21/12/06 17:39:21 INFO InputInfoTracker: remove old batch metadata: 1638792559000 ms
21/12/06 17:39:21 INFO BlockManager: Removing RDD 200
21/12/06 17:39:22 INFO JobScheduler: Added jobs for time 1638792562000 ms
21/12/06 17:39:22 INFO JobScheduler: Starting job streaming job 1638792562000 ms.0 from job set of time 1638792562000 ms
21/12/06 17:39:22 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:22 INFO DAGScheduler: Job 142 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000203 s
21/12/06 17:39:22 INFO JobScheduler: Finished job streaming job 1638792562000 ms.0 from job set of time 1638792562000 ms
21/12/06 17:39:22 INFO JobScheduler: Total delay: 0.026 s for time 1638792562000 ms (execution: 0.023 s)
21/12/06 17:39:22 INFO BlockRDD: Removing RDD 201 from persistence list
21/12/06 17:39:22 INFO BlockManager: Removing RDD 201
21/12/06 17:39:22 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[201] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792562000 ms
21/12/06 17:39:22 INFO ReceivedBlockTracker: Deleting batches: 1638792560000 ms
21/12/06 17:39:22 INFO InputInfoTracker: remove old batch metadata: 1638792560000 ms
21/12/06 17:39:22 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:22 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:22 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:22 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:22 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:22 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:22 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:22 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:22 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:22 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:22 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:22 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:23 INFO JobScheduler: Added jobs for time 1638792563000 ms
21/12/06 17:39:23 INFO JobScheduler: Starting job streaming job 1638792563000 ms.0 from job set of time 1638792563000 ms
21/12/06 17:39:23 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:23 INFO DAGScheduler: Job 143 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000101 s
21/12/06 17:39:23 INFO JobScheduler: Finished job streaming job 1638792563000 ms.0 from job set of time 1638792563000 ms
21/12/06 17:39:23 INFO JobScheduler: Total delay: 0.013 s for time 1638792563000 ms (execution: 0.009 s)
21/12/06 17:39:23 INFO BlockRDD: Removing RDD 202 from persistence list
21/12/06 17:39:23 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[202] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792563000 ms
21/12/06 17:39:23 INFO ReceivedBlockTracker: Deleting batches: 1638792561000 ms
21/12/06 17:39:23 INFO InputInfoTracker: remove old batch metadata: 1638792561000 ms
21/12/06 17:39:23 INFO BlockManager: Removing RDD 202
21/12/06 17:39:24 INFO JobScheduler: Added jobs for time 1638792564000 ms
21/12/06 17:39:24 INFO JobScheduler: Starting job streaming job 1638792564000 ms.0 from job set of time 1638792564000 ms
21/12/06 17:39:24 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:24 INFO DAGScheduler: Job 144 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000093 s
21/12/06 17:39:24 INFO JobScheduler: Finished job streaming job 1638792564000 ms.0 from job set of time 1638792564000 ms
21/12/06 17:39:24 INFO JobScheduler: Total delay: 0.015 s for time 1638792564000 ms (execution: 0.013 s)
21/12/06 17:39:24 INFO BlockRDD: Removing RDD 203 from persistence list
21/12/06 17:39:24 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[203] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792564000 ms
21/12/06 17:39:24 INFO BlockManager: Removing RDD 203
21/12/06 17:39:24 INFO ReceivedBlockTracker: Deleting batches: 1638792562000 ms
21/12/06 17:39:24 INFO InputInfoTracker: remove old batch metadata: 1638792562000 ms
21/12/06 17:39:24 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:24 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:24 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:24 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:24 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:24 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:24 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:24 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:24 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:24 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:24 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:24 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:25 INFO JobScheduler: Added jobs for time 1638792565000 ms
21/12/06 17:39:25 INFO JobScheduler: Starting job streaming job 1638792565000 ms.0 from job set of time 1638792565000 ms
21/12/06 17:39:25 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:25 INFO DAGScheduler: Job 145 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000122 s
21/12/06 17:39:25 INFO JobScheduler: Finished job streaming job 1638792565000 ms.0 from job set of time 1638792565000 ms
21/12/06 17:39:25 INFO JobScheduler: Total delay: 0.014 s for time 1638792565000 ms (execution: 0.011 s)
21/12/06 17:39:25 INFO BlockRDD: Removing RDD 204 from persistence list
21/12/06 17:39:25 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[204] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792565000 ms
21/12/06 17:39:25 INFO ReceivedBlockTracker: Deleting batches: 1638792563000 ms
21/12/06 17:39:25 INFO InputInfoTracker: remove old batch metadata: 1638792563000 ms
21/12/06 17:39:25 INFO BlockManager: Removing RDD 204
21/12/06 17:39:26 INFO JobScheduler: Added jobs for time 1638792566000 ms
21/12/06 17:39:26 INFO JobScheduler: Starting job streaming job 1638792566000 ms.0 from job set of time 1638792566000 ms
21/12/06 17:39:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:26 INFO DAGScheduler: Job 146 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000362 s
21/12/06 17:39:26 INFO JobScheduler: Finished job streaming job 1638792566000 ms.0 from job set of time 1638792566000 ms
21/12/06 17:39:26 INFO JobScheduler: Total delay: 0.017 s for time 1638792566000 ms (execution: 0.015 s)
21/12/06 17:39:26 INFO BlockRDD: Removing RDD 205 from persistence list
21/12/06 17:39:26 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[205] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792566000 ms
21/12/06 17:39:26 INFO ReceivedBlockTracker: Deleting batches: 1638792564000 ms
21/12/06 17:39:26 INFO InputInfoTracker: remove old batch metadata: 1638792564000 ms
21/12/06 17:39:26 INFO BlockManager: Removing RDD 205
21/12/06 17:39:26 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:26 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:26 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:26 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:26 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:26 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:26 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:26 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:26 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:26 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:26 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:26 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:27 INFO JobScheduler: Added jobs for time 1638792567000 ms
21/12/06 17:39:27 INFO JobScheduler: Starting job streaming job 1638792567000 ms.0 from job set of time 1638792567000 ms
21/12/06 17:39:27 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:27 INFO DAGScheduler: Job 147 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000089 s
21/12/06 17:39:27 INFO JobScheduler: Finished job streaming job 1638792567000 ms.0 from job set of time 1638792567000 ms
21/12/06 17:39:27 INFO JobScheduler: Total delay: 0.016 s for time 1638792567000 ms (execution: 0.013 s)
21/12/06 17:39:27 INFO BlockRDD: Removing RDD 206 from persistence list
21/12/06 17:39:27 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[206] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792567000 ms
21/12/06 17:39:27 INFO ReceivedBlockTracker: Deleting batches: 1638792565000 ms
21/12/06 17:39:27 INFO InputInfoTracker: remove old batch metadata: 1638792565000 ms
21/12/06 17:39:27 INFO BlockManager: Removing RDD 206
21/12/06 17:39:28 INFO JobScheduler: Added jobs for time 1638792568000 ms
21/12/06 17:39:28 INFO JobScheduler: Starting job streaming job 1638792568000 ms.0 from job set of time 1638792568000 ms
21/12/06 17:39:28 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:28 INFO DAGScheduler: Job 148 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000084 s
21/12/06 17:39:28 INFO JobScheduler: Finished job streaming job 1638792568000 ms.0 from job set of time 1638792568000 ms
21/12/06 17:39:28 INFO JobScheduler: Total delay: 0.015 s for time 1638792568000 ms (execution: 0.014 s)
21/12/06 17:39:28 INFO BlockRDD: Removing RDD 207 from persistence list
21/12/06 17:39:28 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[207] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792568000 ms
21/12/06 17:39:28 INFO ReceivedBlockTracker: Deleting batches: 1638792566000 ms
21/12/06 17:39:28 INFO InputInfoTracker: remove old batch metadata: 1638792566000 ms
21/12/06 17:39:28 INFO BlockManager: Removing RDD 207
21/12/06 17:39:28 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:28 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:28 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:28 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:28 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:28 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:28 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:28 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:28 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:28 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:28 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:28 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:29 INFO JobScheduler: Added jobs for time 1638792569000 ms
21/12/06 17:39:29 INFO JobScheduler: Starting job streaming job 1638792569000 ms.0 from job set of time 1638792569000 ms
21/12/06 17:39:29 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:29 INFO DAGScheduler: Job 149 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000102 s
21/12/06 17:39:29 INFO JobScheduler: Finished job streaming job 1638792569000 ms.0 from job set of time 1638792569000 ms
21/12/06 17:39:29 INFO JobScheduler: Total delay: 0.017 s for time 1638792569000 ms (execution: 0.015 s)
21/12/06 17:39:29 INFO BlockRDD: Removing RDD 208 from persistence list
21/12/06 17:39:29 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[208] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792569000 ms
21/12/06 17:39:29 INFO ReceivedBlockTracker: Deleting batches: 1638792567000 ms
21/12/06 17:39:29 INFO BlockManager: Removing RDD 208
21/12/06 17:39:29 INFO InputInfoTracker: remove old batch metadata: 1638792567000 ms
21/12/06 17:39:30 INFO JobScheduler: Added jobs for time 1638792570000 ms
21/12/06 17:39:30 INFO JobScheduler: Starting job streaming job 1638792570000 ms.0 from job set of time 1638792570000 ms
21/12/06 17:39:30 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:30 INFO DAGScheduler: Job 150 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000145 s
21/12/06 17:39:30 INFO JobScheduler: Finished job streaming job 1638792570000 ms.0 from job set of time 1638792570000 ms
21/12/06 17:39:30 INFO JobScheduler: Total delay: 0.012 s for time 1638792570000 ms (execution: 0.011 s)
21/12/06 17:39:30 INFO BlockRDD: Removing RDD 209 from persistence list
21/12/06 17:39:30 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[209] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792570000 ms
21/12/06 17:39:30 INFO ReceivedBlockTracker: Deleting batches: 1638792568000 ms
21/12/06 17:39:30 INFO BlockManager: Removing RDD 209
21/12/06 17:39:30 INFO InputInfoTracker: remove old batch metadata: 1638792568000 ms
21/12/06 17:39:30 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:30 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:30 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:30 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:30 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:30 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:30 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:30 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:30 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:30 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:30 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:30 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:31 INFO JobScheduler: Added jobs for time 1638792571000 ms
21/12/06 17:39:31 INFO JobScheduler: Starting job streaming job 1638792571000 ms.0 from job set of time 1638792571000 ms
21/12/06 17:39:31 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:31 INFO DAGScheduler: Job 151 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000198 s
21/12/06 17:39:31 INFO JobScheduler: Finished job streaming job 1638792571000 ms.0 from job set of time 1638792571000 ms
21/12/06 17:39:31 INFO JobScheduler: Total delay: 0.012 s for time 1638792571000 ms (execution: 0.010 s)
21/12/06 17:39:31 INFO BlockRDD: Removing RDD 210 from persistence list
21/12/06 17:39:31 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[210] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792571000 ms
21/12/06 17:39:31 INFO ReceivedBlockTracker: Deleting batches: 1638792569000 ms
21/12/06 17:39:31 INFO InputInfoTracker: remove old batch metadata: 1638792569000 ms
21/12/06 17:39:31 INFO BlockManager: Removing RDD 210
21/12/06 17:39:32 INFO JobScheduler: Added jobs for time 1638792572000 ms
21/12/06 17:39:32 INFO JobScheduler: Starting job streaming job 1638792572000 ms.0 from job set of time 1638792572000 ms
21/12/06 17:39:32 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:32 INFO DAGScheduler: Job 152 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000161 s
21/12/06 17:39:32 INFO JobScheduler: Finished job streaming job 1638792572000 ms.0 from job set of time 1638792572000 ms
21/12/06 17:39:32 INFO JobScheduler: Total delay: 0.022 s for time 1638792572000 ms (execution: 0.021 s)
21/12/06 17:39:32 INFO BlockRDD: Removing RDD 211 from persistence list
21/12/06 17:39:32 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[211] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792572000 ms
21/12/06 17:39:32 INFO ReceivedBlockTracker: Deleting batches: 1638792570000 ms
21/12/06 17:39:32 INFO InputInfoTracker: remove old batch metadata: 1638792570000 ms
21/12/06 17:39:32 INFO BlockManager: Removing RDD 211
21/12/06 17:39:32 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:32 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:32 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:32 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:32 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:32 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:32 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:32 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:32 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:32 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:32 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:32 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:33 INFO JobScheduler: Added jobs for time 1638792573000 ms
21/12/06 17:39:33 INFO JobScheduler: Starting job streaming job 1638792573000 ms.0 from job set of time 1638792573000 ms
21/12/06 17:39:33 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:33 INFO DAGScheduler: Job 153 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000222 s
21/12/06 17:39:33 INFO JobScheduler: Finished job streaming job 1638792573000 ms.0 from job set of time 1638792573000 ms
21/12/06 17:39:33 INFO JobScheduler: Total delay: 0.017 s for time 1638792573000 ms (execution: 0.012 s)
21/12/06 17:39:33 INFO BlockRDD: Removing RDD 212 from persistence list
21/12/06 17:39:33 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[212] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792573000 ms
21/12/06 17:39:33 INFO ReceivedBlockTracker: Deleting batches: 1638792571000 ms
21/12/06 17:39:33 INFO InputInfoTracker: remove old batch metadata: 1638792571000 ms
21/12/06 17:39:33 INFO BlockManager: Removing RDD 212
21/12/06 17:39:34 INFO JobScheduler: Added jobs for time 1638792574000 ms
21/12/06 17:39:34 INFO JobScheduler: Starting job streaming job 1638792574000 ms.0 from job set of time 1638792574000 ms
21/12/06 17:39:34 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:34 INFO DAGScheduler: Job 154 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000156 s
21/12/06 17:39:34 INFO JobScheduler: Finished job streaming job 1638792574000 ms.0 from job set of time 1638792574000 ms
21/12/06 17:39:34 INFO JobScheduler: Total delay: 0.033 s for time 1638792574000 ms (execution: 0.031 s)
21/12/06 17:39:34 INFO BlockRDD: Removing RDD 213 from persistence list
21/12/06 17:39:34 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[213] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792574000 ms
21/12/06 17:39:34 INFO ReceivedBlockTracker: Deleting batches: 1638792572000 ms
21/12/06 17:39:34 INFO InputInfoTracker: remove old batch metadata: 1638792572000 ms
21/12/06 17:39:34 INFO BlockManager: Removing RDD 213
21/12/06 17:39:34 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:34 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:34 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:34 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:34 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:34 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:34 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:34 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:34 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:34 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:34 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:34 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:35 INFO JobScheduler: Added jobs for time 1638792575000 ms
21/12/06 17:39:35 INFO JobScheduler: Starting job streaming job 1638792575000 ms.0 from job set of time 1638792575000 ms
21/12/06 17:39:35 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:35 INFO DAGScheduler: Job 155 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000255 s
21/12/06 17:39:35 INFO JobScheduler: Finished job streaming job 1638792575000 ms.0 from job set of time 1638792575000 ms
21/12/06 17:39:35 INFO JobScheduler: Total delay: 0.019 s for time 1638792575000 ms (execution: 0.017 s)
21/12/06 17:39:35 INFO BlockRDD: Removing RDD 214 from persistence list
21/12/06 17:39:35 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[214] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792575000 ms
21/12/06 17:39:35 INFO ReceivedBlockTracker: Deleting batches: 1638792573000 ms
21/12/06 17:39:35 INFO InputInfoTracker: remove old batch metadata: 1638792573000 ms
21/12/06 17:39:35 INFO BlockManager: Removing RDD 214
21/12/06 17:39:36 INFO JobScheduler: Added jobs for time 1638792576000 ms
21/12/06 17:39:36 INFO JobScheduler: Starting job streaming job 1638792576000 ms.0 from job set of time 1638792576000 ms
21/12/06 17:39:36 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:36 INFO DAGScheduler: Job 156 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000299 s
21/12/06 17:39:36 INFO JobScheduler: Finished job streaming job 1638792576000 ms.0 from job set of time 1638792576000 ms
21/12/06 17:39:36 INFO JobScheduler: Total delay: 0.027 s for time 1638792576000 ms (execution: 0.025 s)
21/12/06 17:39:36 INFO BlockRDD: Removing RDD 215 from persistence list
21/12/06 17:39:36 INFO BlockManager: Removing RDD 215
21/12/06 17:39:36 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[215] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792576000 ms
21/12/06 17:39:36 INFO ReceivedBlockTracker: Deleting batches: 1638792574000 ms
21/12/06 17:39:36 INFO InputInfoTracker: remove old batch metadata: 1638792574000 ms
21/12/06 17:39:36 INFO ReceiverSupervisorImpl: Starting receiver again
21/12/06 17:39:36 INFO ReceiverTracker: Registered receiver for stream 0 from 192.168.0.148:35859
21/12/06 17:39:36 INFO ReceiverSupervisorImpl: Starting receiver 0
21/12/06 17:39:36 INFO SocketReceiver: Connecting to localhost:6100
21/12/06 17:39:36 INFO ReceiverSupervisorImpl: Called receiver 0 onStart
21/12/06 17:39:36 INFO ReceiverSupervisorImpl: Receiver started again
21/12/06 17:39:36 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error connecting to localhost:6100
java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:36 INFO ReceiverSupervisorImpl: Stopping receiver with message: Restarting receiver with delay 2000ms: Error connecting to localhost:6100: java.net.ConnectException: Connection refused (Connection refused)
21/12/06 17:39:36 INFO ReceiverSupervisorImpl: Called receiver onStop
21/12/06 17:39:36 INFO ReceiverSupervisorImpl: Deregistering receiver 0
21/12/06 17:39:36 ERROR ReceiverTracker: Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:6100 - java.net.ConnectException: Connection refused (Connection refused)
	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:609)
	at java.base/java.net.Socket.connect(Socket.java:558)
	at java.base/java.net.Socket.<init>(Socket.java:454)
	at java.base/java.net.Socket.<init>(Socket.java:231)
	at org.apache.spark.streaming.dstream.SocketReceiver.onStart(SocketInputDStream.scala:61)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.startReceiver(ReceiverSupervisor.scala:149)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:198)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

21/12/06 17:39:36 INFO ReceiverSupervisorImpl: Stopped receiver 0
21/12/06 17:39:37 INFO JobScheduler: Added jobs for time 1638792577000 ms
21/12/06 17:39:37 INFO JobScheduler: Starting job streaming job 1638792577000 ms.0 from job set of time 1638792577000 ms
21/12/06 17:39:37 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:37 INFO DAGScheduler: Job 157 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000236 s
21/12/06 17:39:37 INFO JobScheduler: Finished job streaming job 1638792577000 ms.0 from job set of time 1638792577000 ms
21/12/06 17:39:37 INFO JobScheduler: Total delay: 0.026 s for time 1638792577000 ms (execution: 0.023 s)
21/12/06 17:39:37 INFO BlockRDD: Removing RDD 216 from persistence list
21/12/06 17:39:37 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[216] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792577000 ms
21/12/06 17:39:37 INFO ReceivedBlockTracker: Deleting batches: 1638792575000 ms
21/12/06 17:39:37 INFO InputInfoTracker: remove old batch metadata: 1638792575000 ms
21/12/06 17:39:37 INFO BlockManager: Removing RDD 216
21/12/06 17:39:38 INFO JobScheduler: Added jobs for time 1638792578000 ms
21/12/06 17:39:38 INFO JobScheduler: Starting job streaming job 1638792578000 ms.0 from job set of time 1638792578000 ms
21/12/06 17:39:38 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442
21/12/06 17:39:38 INFO DAGScheduler: Job 158 finished: call at /opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:2442, took 0.000416 s
21/12/06 17:39:38 INFO JobScheduler: Finished job streaming job 1638792578000 ms.0 from job set of time 1638792578000 ms
21/12/06 17:39:38 INFO JobScheduler: Total delay: 0.031 s for time 1638792578000 ms (execution: 0.029 s)
21/12/06 17:39:38 INFO BlockRDD: Removing RDD 217 from persistence list
21/12/06 17:39:38 INFO SocketInputDStream: Removing blocks of RDD BlockRDD[217] at socketTextStream at NativeMethodAccessorImpl.java:0 of time 1638792578000 ms
21/12/06 17:39:38 INFO ReceivedBlockTracker: Deleting batches: 1638792576000 ms
21/12/06 17:39:38 INFO InputInfoTracker: remove old batch metadata: 1638792576000 ms
21/12/06 17:39:38 INFO BlockManager: Removing RDD 217
21/12/06 17:39:38 INFO SparkUI: Stopped Spark web UI at http://192.168.0.148:4040
21/12/06 17:39:38 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1085)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1083)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1083)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2463)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2369)
	at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2069)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1419)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2069)
	at org.apache.spark.deploy.SparkSubmit.$anonfun$runMain$13(SparkSubmit.scala:959)
	at org.apache.spark.deploy.SparkSubmit.$anonfun$runMain$13$adapted(SparkSubmit.scala:959)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:959)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1039)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1048)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/12/06 17:39:38 INFO ReceiverTracker: Restarting Receiver 0
21/12/06 17:39:38 INFO DAGScheduler: ResultStage 0 (start at NativeMethodAccessorImpl.java:0) failed in 150.122 s due to Stage cancelled because SparkContext was shut down
21/12/06 17:39:38 ERROR Inbox: Ignoring error
java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.base/java.lang.Thread.run(Thread.java:829)

The currently active SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.base/java.lang.Thread.run(Thread.java:829)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
	at org.apache.spark.SparkContext.$anonfun$makeRDD$2(SparkContext.scala:901)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.SparkContext.withScope(SparkContext.scala:786)
	at org.apache.spark.SparkContext.makeRDD(SparkContext.scala:900)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.org$apache$spark$streaming$scheduler$ReceiverTracker$ReceiverTrackerEndpoint$$startReceiver(ReceiverTracker.scala:609)
	at org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$receive$1.applyOrElse(ReceiverTracker.scala:496)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
21/12/06 17:39:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/12/06 17:39:38 INFO MemoryStore: MemoryStore cleared
21/12/06 17:39:38 INFO BlockManager: BlockManager stopped
21/12/06 17:39:38 INFO BlockManagerMaster: BlockManagerMaster stopped
21/12/06 17:39:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/12/06 17:39:38 INFO SparkContext: Successfully stopped SparkContext
21/12/06 17:39:38 INFO StreamingContext: Invoking stop(stopGracefully=false) from shutdown hook
21/12/06 17:39:38 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@64b8c196[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@6817791d[Wrapped task = org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1@6963028d]] rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7e95e802[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
21/12/06 17:39:38 ERROR Utils: Uncaught exception in thread shutdown-hook-0
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
	at org.apache.spark.streaming.scheduler.ReceiverTracker.stop(ReceiverTracker.scala:172)
	at org.apache.spark.streaming.scheduler.JobScheduler.stop(JobScheduler.scala:113)
	at org.apache.spark.streaming.StreamingContext.$anonfun$stop$3(StreamingContext.scala:688)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1419)
	at org.apache.spark.streaming.StreamingContext.stop(StreamingContext.scala:688)
	at org.apache.spark.streaming.StreamingContext.stopOnShutdown(StreamingContext.scala:724)
	at org.apache.spark.streaming.StreamingContext.$anonfun$start$4(StreamingContext.scala:606)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:174)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)
	at org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:555)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:559)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:102)
	... 22 more
21/12/06 17:39:38 INFO StreamingContext: StreamingContext stopped successfully
21/12/06 17:39:38 INFO ShutdownHookManager: Shutdown hook called
21/12/06 17:39:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-1544335e-2741-42d8-8413-d97d2d527a9f
21/12/06 17:39:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-bdb6c40e-a618-45eb-9b0f-4f89d39027be
21/12/06 17:39:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-1544335e-2741-42d8-8413-d97d2d527a9f/pyspark-553e0240-21b9-4b78-a43a-e8cbcdc65129
